{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](https://bcourses.berkeley.edu/courses/1453965/assignments/7738616) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs294_129.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "  \"\"\"\n",
    "  Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "  it for the linear classifier. These are the same steps as we used for the\n",
    "  SVM, but condensed to a single function.  \n",
    "  \"\"\"\n",
    "  # Load the raw CIFAR-10 data\n",
    "  cifar10_dir = 'cs294_129/datasets/cifar-10-batches-py'\n",
    "  X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "  # subsample the data\n",
    "  mask = range(num_training, num_training + num_validation)\n",
    "  X_val = X_train[mask]\n",
    "  y_val = y_train[mask]\n",
    "  mask = range(num_training)\n",
    "  X_train = X_train[mask]\n",
    "  y_train = y_train[mask]\n",
    "  mask = range(num_test)\n",
    "  X_test = X_test[mask]\n",
    "  y_test = y_test[mask]\n",
    "  mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "  X_dev = X_train[mask]\n",
    "  y_dev = y_train[mask]\n",
    "  \n",
    "  # Preprocessing: reshape the image data into rows\n",
    "  X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "  X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "  X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "  X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "  \n",
    "  # Normalize the data: subtract the mean image\n",
    "  mean_image = np.mean(X_train, axis = 0)\n",
    "  X_train -= mean_image\n",
    "  X_val -= mean_image\n",
    "  X_test -= mean_image\n",
    "  X_dev -= mean_image\n",
    "  \n",
    "  # add bias dimension and transform into columns\n",
    "  X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "  X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "  X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "  X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "  \n",
    "  return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape\n",
    "print 'dev data shape: ', X_dev.shape\n",
    "print 'dev labels shape: ', y_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs294_129/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.314436\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs294_129/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs294_129.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print 'loss: %f' % loss\n",
    "print 'sanity check: %f' % (-np.log(0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** \n",
    "- Recap softmax_loss = -log(probabilistic_interpretation)\n",
    "- With random inited weight, the classification's accruacy is similar to random guessing between 10 classes, with equals to 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.050046 analytic: 0.050046, relative error: 1.710582e-06\n",
      "numerical: -0.905728 analytic: -0.905728, relative error: 5.163847e-08\n",
      "numerical: 2.343667 analytic: 2.343667, relative error: 4.447936e-08\n",
      "numerical: 0.706169 analytic: 0.706169, relative error: 5.513362e-09\n",
      "numerical: -0.327939 analytic: -0.327939, relative error: 5.883238e-08\n",
      "numerical: -1.018838 analytic: -1.018838, relative error: 1.747444e-08\n",
      "numerical: 2.750638 analytic: 2.750638, relative error: 1.221036e-08\n",
      "numerical: -1.144331 analytic: -1.144331, relative error: 3.616569e-08\n",
      "numerical: 1.144965 analytic: 1.144965, relative error: 3.589995e-08\n",
      "numerical: -0.251430 analytic: -0.251430, relative error: 7.545938e-08\n",
      "numerical: -2.059142 analytic: -2.059142, relative error: 2.606311e-09\n",
      "numerical: 1.071423 analytic: 1.071423, relative error: 4.380411e-08\n",
      "numerical: -1.971369 analytic: -1.971369, relative error: 2.392727e-08\n",
      "numerical: -2.051850 analytic: -2.051850, relative error: 2.393667e-08\n",
      "numerical: 1.376189 analytic: 1.376189, relative error: 2.271450e-08\n",
      "numerical: -1.238570 analytic: -1.238570, relative error: 3.183653e-08\n",
      "numerical: 1.496379 analytic: 1.496379, relative error: 1.025298e-08\n",
      "numerical: 1.137601 analytic: 1.137601, relative error: 5.790302e-08\n",
      "numerical: -0.180885 analytic: -0.180885, relative error: 2.079139e-08\n",
      "numerical: 0.603655 analytic: 0.603655, relative error: 5.590978e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs294_129.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 1e2)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 1e2)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.314436e+00 computed in 0.103099s\n",
      "vectorized loss: 2.314436e+00 computed in 0.006266s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'naive loss: %e computed in %fs' % (loss_naive, toc - tic)\n",
    "\n",
    "from cs294_129.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.00001)\n",
    "toc = time.time()\n",
    "print 'vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic)\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print 'Loss difference: %f' % np.abs(loss_naive - loss_vectorized)\n",
    "print 'Gradient difference: %f' % grad_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 114.509988\n",
      "iteration 100 / 1500: loss 98.303158\n",
      "iteration 200 / 1500: loss 85.634728\n",
      "iteration 300 / 1500: loss 74.223824\n",
      "iteration 400 / 1500: loss 64.644375\n",
      "iteration 500 / 1500: loss 56.197523\n",
      "iteration 600 / 1500: loss 49.089113\n",
      "iteration 700 / 1500: loss 42.828951\n",
      "iteration 800 / 1500: loss 37.367359\n",
      "iteration 900 / 1500: loss 32.682671\n",
      "iteration 1000 / 1500: loss 28.635455\n",
      "iteration 1100 / 1500: loss 24.999131\n",
      "iteration 1200 / 1500: loss 22.076185\n",
      "iteration 1300 / 1500: loss 19.324939\n",
      "iteration 1400 / 1500: loss 17.144582\n",
      "iteration 0 / 1500: loss 126.600503\n",
      "iteration 100 / 1500: loss 106.498100\n",
      "iteration 200 / 1500: loss 90.613094\n",
      "iteration 300 / 1500: loss 77.207139\n",
      "iteration 400 / 1500: loss 65.837386\n",
      "iteration 500 / 1500: loss 56.145752\n",
      "iteration 600 / 1500: loss 48.293673\n",
      "iteration 700 / 1500: loss 41.296046\n",
      "iteration 800 / 1500: loss 35.514585\n",
      "iteration 900 / 1500: loss 30.508022\n",
      "iteration 1000 / 1500: loss 26.156481\n",
      "iteration 1100 / 1500: loss 22.498218\n",
      "iteration 1200 / 1500: loss 19.502528\n",
      "iteration 1300 / 1500: loss 16.803796\n",
      "iteration 1400 / 1500: loss 14.631989\n",
      "iteration 0 / 1500: loss 143.688148\n",
      "iteration 100 / 1500: loss 118.339818\n",
      "iteration 200 / 1500: loss 99.016250\n",
      "iteration 300 / 1500: loss 82.999080\n",
      "iteration 400 / 1500: loss 69.482287\n",
      "iteration 500 / 1500: loss 57.908161\n",
      "iteration 600 / 1500: loss 48.694659\n",
      "iteration 700 / 1500: loss 40.760084\n",
      "iteration 800 / 1500: loss 34.396836\n",
      "iteration 900 / 1500: loss 28.950273\n",
      "iteration 1000 / 1500: loss 24.463317\n",
      "iteration 1100 / 1500: loss 20.938108\n",
      "iteration 1200 / 1500: loss 17.569575\n",
      "iteration 1300 / 1500: loss 15.043057\n",
      "iteration 1400 / 1500: loss 12.907917\n",
      "iteration 0 / 1500: loss 160.169780\n",
      "iteration 100 / 1500: loss 129.482169\n",
      "iteration 200 / 1500: loss 105.682899\n",
      "iteration 300 / 1500: loss 86.462278\n",
      "iteration 400 / 1500: loss 71.180804\n",
      "iteration 500 / 1500: loss 58.466710\n",
      "iteration 600 / 1500: loss 48.139027\n",
      "iteration 700 / 1500: loss 39.748567\n",
      "iteration 800 / 1500: loss 32.823916\n",
      "iteration 900 / 1500: loss 27.172340\n",
      "iteration 1000 / 1500: loss 22.684272\n",
      "iteration 1100 / 1500: loss 18.809112\n",
      "iteration 1200 / 1500: loss 15.706729\n",
      "iteration 1300 / 1500: loss 13.299198\n",
      "iteration 1400 / 1500: loss 11.135734\n",
      "iteration 0 / 1500: loss 172.469716\n",
      "iteration 100 / 1500: loss 137.579092\n",
      "iteration 200 / 1500: loss 110.498853\n",
      "iteration 300 / 1500: loss 88.601682\n",
      "iteration 400 / 1500: loss 71.558478\n",
      "iteration 500 / 1500: loss 57.677994\n",
      "iteration 600 / 1500: loss 46.492516\n",
      "iteration 700 / 1500: loss 37.696268\n",
      "iteration 800 / 1500: loss 30.528005\n",
      "iteration 900 / 1500: loss 24.890991\n",
      "iteration 1000 / 1500: loss 20.217580\n",
      "iteration 1100 / 1500: loss 16.565492\n",
      "iteration 1200 / 1500: loss 13.699206\n",
      "iteration 1300 / 1500: loss 11.460458\n",
      "iteration 1400 / 1500: loss 9.582918\n",
      "iteration 0 / 1500: loss 189.890694\n",
      "iteration 100 / 1500: loss 148.164139\n",
      "iteration 200 / 1500: loss 116.359360\n",
      "iteration 300 / 1500: loss 91.867841\n",
      "iteration 400 / 1500: loss 72.300243\n",
      "iteration 500 / 1500: loss 57.426897\n",
      "iteration 600 / 1500: loss 45.298509\n",
      "iteration 700 / 1500: loss 35.958311\n",
      "iteration 800 / 1500: loss 28.730211\n",
      "iteration 900 / 1500: loss 23.059842\n",
      "iteration 1000 / 1500: loss 18.504645\n",
      "iteration 1100 / 1500: loss 14.892683\n",
      "iteration 1200 / 1500: loss 12.120306\n",
      "iteration 1300 / 1500: loss 9.907975\n",
      "iteration 1400 / 1500: loss 8.208948\n",
      "iteration 0 / 1500: loss 205.754544\n",
      "iteration 100 / 1500: loss 157.852686\n",
      "iteration 200 / 1500: loss 121.826197\n",
      "iteration 300 / 1500: loss 94.201121\n",
      "iteration 400 / 1500: loss 72.844533\n",
      "iteration 500 / 1500: loss 56.474564\n",
      "iteration 600 / 1500: loss 43.876628\n",
      "iteration 700 / 1500: loss 34.236369\n",
      "iteration 800 / 1500: loss 26.809707\n",
      "iteration 900 / 1500: loss 20.981268\n",
      "iteration 1000 / 1500: loss 16.612212\n",
      "iteration 1100 / 1500: loss 13.274800\n",
      "iteration 1200 / 1500: loss 10.588814\n",
      "iteration 1300 / 1500: loss 8.662003\n",
      "iteration 1400 / 1500: loss 7.105052\n",
      "iteration 0 / 1500: loss 722.491783\n",
      "iteration 100 / 1500: loss 281.451536\n",
      "iteration 200 / 1500: loss 110.593943\n",
      "iteration 300 / 1500: loss 44.237606\n",
      "iteration 400 / 1500: loss 18.520040\n",
      "iteration 500 / 1500: loss 8.428735\n",
      "iteration 600 / 1500: loss 4.548315\n",
      "iteration 700 / 1500: loss 3.022219\n",
      "iteration 800 / 1500: loss 2.441224\n",
      "iteration 900 / 1500: loss 2.199986\n",
      "iteration 1000 / 1500: loss 2.157612\n",
      "iteration 1100 / 1500: loss 2.042281\n",
      "iteration 1200 / 1500: loss 2.142079\n",
      "iteration 1300 / 1500: loss 2.085593\n",
      "iteration 1400 / 1500: loss 2.054008\n",
      "iteration 0 / 1500: loss 751.578044\n",
      "iteration 100 / 1500: loss 286.996548\n",
      "iteration 200 / 1500: loss 110.608512\n",
      "iteration 300 / 1500: loss 43.405689\n",
      "iteration 400 / 1500: loss 17.836402\n",
      "iteration 500 / 1500: loss 8.019927\n",
      "iteration 600 / 1500: loss 4.376566\n",
      "iteration 700 / 1500: loss 2.989835\n",
      "iteration 800 / 1500: loss 2.392841\n",
      "iteration 900 / 1500: loss 2.203734\n",
      "iteration 1000 / 1500: loss 2.138620\n",
      "iteration 1100 / 1500: loss 2.126948\n",
      "iteration 1200 / 1500: loss 2.008997\n",
      "iteration 1300 / 1500: loss 2.081037\n",
      "iteration 1400 / 1500: loss 2.107070\n",
      "iteration 0 / 1500: loss 755.625971\n",
      "iteration 100 / 1500: loss 282.973151\n",
      "iteration 200 / 1500: loss 106.893204\n",
      "iteration 300 / 1500: loss 41.189160\n",
      "iteration 400 / 1500: loss 16.601246\n",
      "iteration 500 / 1500: loss 7.561668\n",
      "iteration 600 / 1500: loss 4.164717\n",
      "iteration 700 / 1500: loss 2.860526\n",
      "iteration 800 / 1500: loss 2.420137\n",
      "iteration 900 / 1500: loss 2.260352\n",
      "iteration 1000 / 1500: loss 2.039856\n",
      "iteration 1100 / 1500: loss 2.108512\n",
      "iteration 1200 / 1500: loss 2.067835\n",
      "iteration 1300 / 1500: loss 2.104032\n",
      "iteration 1400 / 1500: loss 2.099320\n",
      "iteration 0 / 1500: loss 773.483431\n",
      "iteration 100 / 1500: loss 284.006543\n",
      "iteration 200 / 1500: loss 105.121048\n",
      "iteration 300 / 1500: loss 39.906603\n",
      "iteration 400 / 1500: loss 15.898174\n",
      "iteration 500 / 1500: loss 7.135108\n",
      "iteration 600 / 1500: loss 3.933996\n",
      "iteration 700 / 1500: loss 2.743701\n",
      "iteration 800 / 1500: loss 2.371159\n",
      "iteration 900 / 1500: loss 2.191169\n",
      "iteration 1000 / 1500: loss 2.132055\n",
      "iteration 1100 / 1500: loss 2.159006\n",
      "iteration 1200 / 1500: loss 2.081593\n",
      "iteration 1300 / 1500: loss 2.090794\n",
      "iteration 1400 / 1500: loss 2.051977\n",
      "iteration 0 / 1500: loss 785.921413\n",
      "iteration 100 / 1500: loss 282.352014\n",
      "iteration 200 / 1500: loss 102.590481\n",
      "iteration 300 / 1500: loss 38.130519\n",
      "iteration 400 / 1500: loss 15.012990\n",
      "iteration 500 / 1500: loss 6.728081\n",
      "iteration 600 / 1500: loss 3.776104\n",
      "iteration 700 / 1500: loss 2.721947\n",
      "iteration 800 / 1500: loss 2.315507\n",
      "iteration 900 / 1500: loss 2.157309\n",
      "iteration 1000 / 1500: loss 2.098184\n",
      "iteration 1100 / 1500: loss 2.042666\n",
      "iteration 1200 / 1500: loss 2.110357\n",
      "iteration 1300 / 1500: loss 2.112735\n",
      "iteration 1400 / 1500: loss 2.081364\n",
      "iteration 0 / 1500: loss 797.019385\n",
      "iteration 100 / 1500: loss 280.942622\n",
      "iteration 200 / 1500: loss 99.846904\n",
      "iteration 300 / 1500: loss 36.512502\n",
      "iteration 400 / 1500: loss 14.134400\n",
      "iteration 500 / 1500: loss 6.252271\n",
      "iteration 600 / 1500: loss 3.632156\n",
      "iteration 700 / 1500: loss 2.688620\n",
      "iteration 800 / 1500: loss 2.260527\n",
      "iteration 900 / 1500: loss 2.146460\n",
      "iteration 1000 / 1500: loss 2.159492\n",
      "iteration 1100 / 1500: loss 2.079291\n",
      "iteration 1200 / 1500: loss 2.058829\n",
      "iteration 1300 / 1500: loss 2.057538\n",
      "iteration 1400 / 1500: loss 2.068178\n",
      "iteration 0 / 1500: loss 836.744765\n",
      "iteration 100 / 1500: loss 289.081506\n",
      "iteration 200 / 1500: loss 100.840313\n",
      "iteration 300 / 1500: loss 36.115493\n",
      "iteration 400 / 1500: loss 13.748500\n",
      "iteration 500 / 1500: loss 6.204822\n",
      "iteration 600 / 1500: loss 3.490686\n",
      "iteration 700 / 1500: loss 2.591714\n",
      "iteration 800 / 1500: loss 2.261939\n",
      "iteration 900 / 1500: loss 2.127193\n",
      "iteration 1000 / 1500: loss 2.125748\n",
      "iteration 1100 / 1500: loss 2.053345\n",
      "iteration 1200 / 1500: loss 2.069686\n",
      "iteration 1300 / 1500: loss 2.056502\n",
      "iteration 1400 / 1500: loss 2.063929\n",
      "iteration 0 / 1500: loss 112.290268\n",
      "iteration 100 / 1500: loss 73.051950\n",
      "iteration 200 / 1500: loss 48.300558\n",
      "iteration 300 / 1500: loss 32.112575\n",
      "iteration 400 / 1500: loss 21.677539\n",
      "iteration 500 / 1500: loss 14.709146\n",
      "iteration 600 / 1500: loss 10.325357\n",
      "iteration 700 / 1500: loss 7.539680\n",
      "iteration 800 / 1500: loss 5.593481\n",
      "iteration 900 / 1500: loss 4.236237\n",
      "iteration 1000 / 1500: loss 3.477725\n",
      "iteration 1100 / 1500: loss 2.881806\n",
      "iteration 1200 / 1500: loss 2.689367\n",
      "iteration 1300 / 1500: loss 2.272421\n",
      "iteration 1400 / 1500: loss 2.160232\n",
      "iteration 0 / 1500: loss 128.429850\n",
      "iteration 100 / 1500: loss 78.210421\n",
      "iteration 200 / 1500: loss 48.702594\n",
      "iteration 300 / 1500: loss 30.649939\n",
      "iteration 400 / 1500: loss 19.667308\n",
      "iteration 500 / 1500: loss 12.805017\n",
      "iteration 600 / 1500: loss 8.527768\n",
      "iteration 700 / 1500: loss 6.115229\n",
      "iteration 800 / 1500: loss 4.442743\n",
      "iteration 900 / 1500: loss 3.530987\n",
      "iteration 1000 / 1500: loss 2.885875\n",
      "iteration 1100 / 1500: loss 2.445842\n",
      "iteration 1200 / 1500: loss 2.422085\n",
      "iteration 1300 / 1500: loss 2.112013\n",
      "iteration 1400 / 1500: loss 2.131168\n",
      "iteration 0 / 1500: loss 140.967618\n",
      "iteration 100 / 1500: loss 81.437931\n",
      "iteration 200 / 1500: loss 47.862678\n",
      "iteration 300 / 1500: loss 28.660770\n",
      "iteration 400 / 1500: loss 17.369157\n",
      "iteration 500 / 1500: loss 10.923966\n",
      "iteration 600 / 1500: loss 7.056817\n",
      "iteration 700 / 1500: loss 5.022791\n",
      "iteration 800 / 1500: loss 3.656298\n",
      "iteration 900 / 1500: loss 2.975493\n",
      "iteration 1000 / 1500: loss 2.546227\n",
      "iteration 1100 / 1500: loss 2.209510\n",
      "iteration 1200 / 1500: loss 2.112426\n",
      "iteration 1300 / 1500: loss 2.104987\n",
      "iteration 1400 / 1500: loss 2.022517\n",
      "iteration 0 / 1500: loss 159.013430\n",
      "iteration 100 / 1500: loss 86.092001\n",
      "iteration 200 / 1500: loss 47.739312\n",
      "iteration 300 / 1500: loss 26.898228\n",
      "iteration 400 / 1500: loss 15.527103\n",
      "iteration 500 / 1500: loss 9.453064\n",
      "iteration 600 / 1500: loss 5.972484\n",
      "iteration 700 / 1500: loss 4.259528\n",
      "iteration 800 / 1500: loss 3.182987\n",
      "iteration 900 / 1500: loss 2.632027\n",
      "iteration 1000 / 1500: loss 2.306612\n",
      "iteration 1100 / 1500: loss 2.213826\n",
      "iteration 1200 / 1500: loss 1.960045\n",
      "iteration 1300 / 1500: loss 1.999563\n",
      "iteration 1400 / 1500: loss 1.943102\n",
      "iteration 0 / 1500: loss 172.229248\n",
      "iteration 100 / 1500: loss 88.121969\n",
      "iteration 200 / 1500: loss 46.098211\n",
      "iteration 300 / 1500: loss 24.717431\n",
      "iteration 400 / 1500: loss 13.623199\n",
      "iteration 500 / 1500: loss 7.939119\n",
      "iteration 600 / 1500: loss 5.059982\n",
      "iteration 700 / 1500: loss 3.551294\n",
      "iteration 800 / 1500: loss 2.770237\n",
      "iteration 900 / 1500: loss 2.387967\n",
      "iteration 1000 / 1500: loss 2.296920\n",
      "iteration 1100 / 1500: loss 2.037833\n",
      "iteration 1200 / 1500: loss 2.011114\n",
      "iteration 1300 / 1500: loss 1.903690\n",
      "iteration 1400 / 1500: loss 1.925729\n",
      "iteration 0 / 1500: loss 193.293107\n",
      "iteration 100 / 1500: loss 92.510180\n",
      "iteration 200 / 1500: loss 45.631202\n",
      "iteration 300 / 1500: loss 23.064749\n",
      "iteration 400 / 1500: loss 12.120310\n",
      "iteration 500 / 1500: loss 6.851790\n",
      "iteration 600 / 1500: loss 4.376864\n",
      "iteration 700 / 1500: loss 3.094738\n",
      "iteration 800 / 1500: loss 2.532838\n",
      "iteration 900 / 1500: loss 2.223958\n",
      "iteration 1000 / 1500: loss 2.063576\n",
      "iteration 1100 / 1500: loss 2.114436\n",
      "iteration 1200 / 1500: loss 1.911425\n",
      "iteration 1300 / 1500: loss 2.012093\n",
      "iteration 1400 / 1500: loss 1.992876\n",
      "iteration 0 / 1500: loss 206.120611\n",
      "iteration 100 / 1500: loss 93.789498\n",
      "iteration 200 / 1500: loss 43.786157\n",
      "iteration 300 / 1500: loss 20.965912\n",
      "iteration 400 / 1500: loss 10.604797\n",
      "iteration 500 / 1500: loss 5.985560\n",
      "iteration 600 / 1500: loss 3.746580\n",
      "iteration 700 / 1500: loss 2.839209\n",
      "iteration 800 / 1500: loss 2.381343\n",
      "iteration 900 / 1500: loss 2.116868\n",
      "iteration 1000 / 1500: loss 1.946498\n",
      "iteration 1100 / 1500: loss 2.015995\n",
      "iteration 1200 / 1500: loss 1.908469\n",
      "iteration 1300 / 1500: loss 1.974714\n",
      "iteration 1400 / 1500: loss 2.076077\n",
      "iteration 0 / 1500: loss 734.664078\n",
      "iteration 100 / 1500: loss 44.435542\n",
      "iteration 200 / 1500: loss 4.534820\n",
      "iteration 300 / 1500: loss 2.192145\n",
      "iteration 400 / 1500: loss 2.054042\n",
      "iteration 500 / 1500: loss 2.126212\n",
      "iteration 600 / 1500: loss 2.014045\n",
      "iteration 700 / 1500: loss 2.056193\n",
      "iteration 800 / 1500: loss 2.040810\n",
      "iteration 900 / 1500: loss 2.055292\n",
      "iteration 1000 / 1500: loss 2.069483\n",
      "iteration 1100 / 1500: loss 2.051139\n",
      "iteration 1200 / 1500: loss 2.089724\n",
      "iteration 1300 / 1500: loss 2.074985\n",
      "iteration 1400 / 1500: loss 2.107635\n",
      "iteration 0 / 1500: loss 733.094623\n",
      "iteration 100 / 1500: loss 41.904611\n",
      "iteration 200 / 1500: loss 4.252422\n",
      "iteration 300 / 1500: loss 2.187335\n",
      "iteration 400 / 1500: loss 2.107404\n",
      "iteration 500 / 1500: loss 2.110411\n",
      "iteration 600 / 1500: loss 2.109426\n",
      "iteration 700 / 1500: loss 2.084899\n",
      "iteration 800 / 1500: loss 2.071117\n",
      "iteration 900 / 1500: loss 2.153400\n",
      "iteration 1000 / 1500: loss 2.085328\n",
      "iteration 1100 / 1500: loss 2.079204\n",
      "iteration 1200 / 1500: loss 2.167210\n",
      "iteration 1300 / 1500: loss 2.115849\n",
      "iteration 1400 / 1500: loss 2.066864\n",
      "iteration 0 / 1500: loss 763.864269\n",
      "iteration 100 / 1500: loss 41.087053\n",
      "iteration 200 / 1500: loss 4.152286\n",
      "iteration 300 / 1500: loss 2.214271\n",
      "iteration 400 / 1500: loss 2.089656\n",
      "iteration 500 / 1500: loss 2.100151\n",
      "iteration 600 / 1500: loss 2.109237\n",
      "iteration 700 / 1500: loss 2.123181\n",
      "iteration 800 / 1500: loss 2.061812\n",
      "iteration 900 / 1500: loss 2.050531\n",
      "iteration 1000 / 1500: loss 2.076887\n",
      "iteration 1100 / 1500: loss 2.070010\n",
      "iteration 1200 / 1500: loss 2.091065\n",
      "iteration 1300 / 1500: loss 2.076425\n",
      "iteration 1400 / 1500: loss 2.066940\n",
      "iteration 0 / 1500: loss 773.798511\n",
      "iteration 100 / 1500: loss 39.264611\n",
      "iteration 200 / 1500: loss 3.901740\n",
      "iteration 300 / 1500: loss 2.187544\n",
      "iteration 400 / 1500: loss 2.108585\n",
      "iteration 500 / 1500: loss 2.096443\n",
      "iteration 600 / 1500: loss 2.133795\n",
      "iteration 700 / 1500: loss 2.080716\n",
      "iteration 800 / 1500: loss 2.128966\n",
      "iteration 900 / 1500: loss 1.954769\n",
      "iteration 1000 / 1500: loss 2.091572\n",
      "iteration 1100 / 1500: loss 2.056597\n",
      "iteration 1200 / 1500: loss 2.135722\n",
      "iteration 1300 / 1500: loss 2.147174\n",
      "iteration 1400 / 1500: loss 2.073612\n",
      "iteration 0 / 1500: loss 793.286107\n",
      "iteration 100 / 1500: loss 37.929361\n",
      "iteration 200 / 1500: loss 3.738812\n",
      "iteration 300 / 1500: loss 2.161262\n",
      "iteration 400 / 1500: loss 2.093011\n",
      "iteration 500 / 1500: loss 2.107817\n",
      "iteration 600 / 1500: loss 2.112648\n",
      "iteration 700 / 1500: loss 2.102382\n",
      "iteration 800 / 1500: loss 2.114170\n",
      "iteration 900 / 1500: loss 2.121552\n",
      "iteration 1000 / 1500: loss 2.101861\n",
      "iteration 1100 / 1500: loss 2.059766\n",
      "iteration 1200 / 1500: loss 2.074803\n",
      "iteration 1300 / 1500: loss 2.088082\n",
      "iteration 1400 / 1500: loss 2.024266\n",
      "iteration 0 / 1500: loss 795.872747\n",
      "iteration 100 / 1500: loss 35.940071\n",
      "iteration 200 / 1500: loss 3.485418\n",
      "iteration 300 / 1500: loss 2.216903\n",
      "iteration 400 / 1500: loss 2.148235\n",
      "iteration 500 / 1500: loss 2.131683\n",
      "iteration 600 / 1500: loss 2.088037\n",
      "iteration 700 / 1500: loss 2.079946\n",
      "iteration 800 / 1500: loss 2.109445\n",
      "iteration 900 / 1500: loss 2.086536\n",
      "iteration 1000 / 1500: loss 2.140135\n",
      "iteration 1100 / 1500: loss 2.064858\n",
      "iteration 1200 / 1500: loss 2.074789\n",
      "iteration 1300 / 1500: loss 2.083750\n",
      "iteration 1400 / 1500: loss 2.058224\n",
      "iteration 0 / 1500: loss 829.931391\n",
      "iteration 100 / 1500: loss 35.317422\n",
      "iteration 200 / 1500: loss 3.412762\n",
      "iteration 300 / 1500: loss 2.105673\n",
      "iteration 400 / 1500: loss 2.145732\n",
      "iteration 500 / 1500: loss 2.119064\n",
      "iteration 600 / 1500: loss 2.109319\n",
      "iteration 700 / 1500: loss 2.132129\n",
      "iteration 800 / 1500: loss 2.074536\n",
      "iteration 900 / 1500: loss 2.123086\n",
      "iteration 1000 / 1500: loss 2.140793\n",
      "iteration 1100 / 1500: loss 2.126053\n",
      "iteration 1200 / 1500: loss 2.113120\n",
      "iteration 1300 / 1500: loss 2.093726\n",
      "iteration 1400 / 1500: loss 2.107353\n",
      "iteration 0 / 1500: loss 112.841788\n",
      "iteration 100 / 1500: loss 55.409005\n",
      "iteration 200 / 1500: loss 28.082108\n",
      "iteration 300 / 1500: loss 14.835008\n",
      "iteration 400 / 1500: loss 8.345842\n",
      "iteration 500 / 1500: loss 5.049375\n",
      "iteration 600 / 1500: loss 3.529249\n",
      "iteration 700 / 1500: loss 2.753238\n",
      "iteration 800 / 1500: loss 2.307902\n",
      "iteration 900 / 1500: loss 2.211938\n",
      "iteration 1000 / 1500: loss 2.051444\n",
      "iteration 1100 / 1500: loss 1.981254\n",
      "iteration 1200 / 1500: loss 1.987023\n",
      "iteration 1300 / 1500: loss 1.888649\n",
      "iteration 1400 / 1500: loss 1.946806\n",
      "iteration 0 / 1500: loss 126.952883\n",
      "iteration 100 / 1500: loss 56.472935\n",
      "iteration 200 / 1500: loss 26.027062\n",
      "iteration 300 / 1500: loss 12.738248\n",
      "iteration 400 / 1500: loss 6.667132\n",
      "iteration 500 / 1500: loss 4.054048\n",
      "iteration 600 / 1500: loss 2.905047\n",
      "iteration 700 / 1500: loss 2.308450\n",
      "iteration 800 / 1500: loss 2.100414\n",
      "iteration 900 / 1500: loss 1.956357\n",
      "iteration 1000 / 1500: loss 1.961650\n",
      "iteration 1100 / 1500: loss 1.915141\n",
      "iteration 1200 / 1500: loss 1.921530\n",
      "iteration 1300 / 1500: loss 1.953301\n",
      "iteration 1400 / 1500: loss 2.005177\n",
      "iteration 0 / 1500: loss 144.586360\n",
      "iteration 100 / 1500: loss 58.128429\n",
      "iteration 200 / 1500: loss 24.476203\n",
      "iteration 300 / 1500: loss 11.032271\n",
      "iteration 400 / 1500: loss 5.587275\n",
      "iteration 500 / 1500: loss 3.393008\n",
      "iteration 600 / 1500: loss 2.629403\n",
      "iteration 700 / 1500: loss 2.192715\n",
      "iteration 800 / 1500: loss 2.115955\n",
      "iteration 900 / 1500: loss 2.038995\n",
      "iteration 1000 / 1500: loss 1.891062\n",
      "iteration 1100 / 1500: loss 1.967180\n",
      "iteration 1200 / 1500: loss 2.029220\n",
      "iteration 1300 / 1500: loss 1.905114\n",
      "iteration 1400 / 1500: loss 1.958120\n",
      "iteration 0 / 1500: loss 158.050023\n",
      "iteration 100 / 1500: loss 57.995962\n",
      "iteration 200 / 1500: loss 22.292651\n",
      "iteration 300 / 1500: loss 9.393616\n",
      "iteration 400 / 1500: loss 4.542497\n",
      "iteration 500 / 1500: loss 2.914935\n",
      "iteration 600 / 1500: loss 2.342729\n",
      "iteration 700 / 1500: loss 2.224113\n",
      "iteration 800 / 1500: loss 1.954514\n",
      "iteration 900 / 1500: loss 2.043316\n",
      "iteration 1000 / 1500: loss 1.987964\n",
      "iteration 1100 / 1500: loss 1.910402\n",
      "iteration 1200 / 1500: loss 2.032022\n",
      "iteration 1300 / 1500: loss 2.008817\n",
      "iteration 1400 / 1500: loss 1.963360\n",
      "iteration 0 / 1500: loss 174.692651\n",
      "iteration 100 / 1500: loss 57.751323\n",
      "iteration 200 / 1500: loss 20.253377\n",
      "iteration 300 / 1500: loss 8.011367\n",
      "iteration 400 / 1500: loss 3.951335\n",
      "iteration 500 / 1500: loss 2.635463\n",
      "iteration 600 / 1500: loss 2.181095\n",
      "iteration 700 / 1500: loss 2.051848\n",
      "iteration 800 / 1500: loss 2.009840\n",
      "iteration 900 / 1500: loss 1.920987\n",
      "iteration 1000 / 1500: loss 1.900975\n",
      "iteration 1100 / 1500: loss 1.991658\n",
      "iteration 1200 / 1500: loss 1.937218\n",
      "iteration 1300 / 1500: loss 2.001368\n",
      "iteration 1400 / 1500: loss 1.950374\n",
      "iteration 0 / 1500: loss 188.780481\n",
      "iteration 100 / 1500: loss 56.895586\n",
      "iteration 200 / 1500: loss 18.350273\n",
      "iteration 300 / 1500: loss 6.752887\n",
      "iteration 400 / 1500: loss 3.322053\n",
      "iteration 500 / 1500: loss 2.350677\n",
      "iteration 600 / 1500: loss 2.069957\n",
      "iteration 700 / 1500: loss 1.935465\n",
      "iteration 800 / 1500: loss 2.060109\n",
      "iteration 900 / 1500: loss 1.902950\n",
      "iteration 1000 / 1500: loss 1.877763\n",
      "iteration 1100 / 1500: loss 1.919017\n",
      "iteration 1200 / 1500: loss 1.974712\n",
      "iteration 1300 / 1500: loss 1.919997\n",
      "iteration 1400 / 1500: loss 1.994032\n",
      "iteration 0 / 1500: loss 207.314760\n",
      "iteration 100 / 1500: loss 56.546290\n",
      "iteration 200 / 1500: loss 16.618542\n",
      "iteration 300 / 1500: loss 5.921166\n",
      "iteration 400 / 1500: loss 2.958168\n",
      "iteration 500 / 1500: loss 2.244644\n",
      "iteration 600 / 1500: loss 2.037555\n",
      "iteration 700 / 1500: loss 1.975446\n",
      "iteration 800 / 1500: loss 1.908548\n",
      "iteration 900 / 1500: loss 2.021139\n",
      "iteration 1000 / 1500: loss 2.037929\n",
      "iteration 1100 / 1500: loss 1.981166\n",
      "iteration 1200 / 1500: loss 1.965745\n",
      "iteration 1300 / 1500: loss 2.063327\n",
      "iteration 1400 / 1500: loss 1.919369\n",
      "iteration 0 / 1500: loss 718.909706\n",
      "iteration 100 / 1500: loss 8.174635\n",
      "iteration 200 / 1500: loss 2.132007\n",
      "iteration 300 / 1500: loss 2.129559\n",
      "iteration 400 / 1500: loss 2.130346\n",
      "iteration 500 / 1500: loss 2.056909\n",
      "iteration 600 / 1500: loss 2.102657\n",
      "iteration 700 / 1500: loss 2.041470\n",
      "iteration 800 / 1500: loss 2.086419\n",
      "iteration 900 / 1500: loss 2.040880\n",
      "iteration 1000 / 1500: loss 2.104302\n",
      "iteration 1100 / 1500: loss 2.081888\n",
      "iteration 1200 / 1500: loss 2.082231\n",
      "iteration 1300 / 1500: loss 1.973765\n",
      "iteration 1400 / 1500: loss 2.052553\n",
      "iteration 0 / 1500: loss 738.492055\n",
      "iteration 100 / 1500: loss 7.660343\n",
      "iteration 200 / 1500: loss 2.076303\n",
      "iteration 300 / 1500: loss 2.080519\n",
      "iteration 400 / 1500: loss 2.092147\n",
      "iteration 500 / 1500: loss 2.103461\n",
      "iteration 600 / 1500: loss 2.121903\n",
      "iteration 700 / 1500: loss 2.081320\n",
      "iteration 800 / 1500: loss 2.190859\n",
      "iteration 900 / 1500: loss 2.149589\n",
      "iteration 1000 / 1500: loss 2.102726\n",
      "iteration 1100 / 1500: loss 2.064822\n",
      "iteration 1200 / 1500: loss 2.044160\n",
      "iteration 1300 / 1500: loss 2.068389\n",
      "iteration 1400 / 1500: loss 2.126790\n",
      "iteration 0 / 1500: loss 770.814513\n",
      "iteration 100 / 1500: loss 7.356468\n",
      "iteration 200 / 1500: loss 2.109394\n",
      "iteration 300 / 1500: loss 2.081457\n",
      "iteration 400 / 1500: loss 2.047705\n",
      "iteration 500 / 1500: loss 2.114211\n",
      "iteration 600 / 1500: loss 2.119601\n",
      "iteration 700 / 1500: loss 2.146136\n",
      "iteration 800 / 1500: loss 2.090287\n",
      "iteration 900 / 1500: loss 2.024220\n",
      "iteration 1000 / 1500: loss 2.133222\n",
      "iteration 1100 / 1500: loss 2.074293\n",
      "iteration 1200 / 1500: loss 2.065631\n",
      "iteration 1300 / 1500: loss 2.110130\n",
      "iteration 1400 / 1500: loss 2.092505\n",
      "iteration 0 / 1500: loss 768.670039\n",
      "iteration 100 / 1500: loss 6.873492\n",
      "iteration 200 / 1500: loss 2.173619\n",
      "iteration 300 / 1500: loss 2.103041\n",
      "iteration 400 / 1500: loss 2.071352\n",
      "iteration 500 / 1500: loss 2.100149\n",
      "iteration 600 / 1500: loss 2.110243\n",
      "iteration 700 / 1500: loss 2.110525\n",
      "iteration 800 / 1500: loss 2.043290\n",
      "iteration 900 / 1500: loss 2.091911\n",
      "iteration 1000 / 1500: loss 2.051125\n",
      "iteration 1100 / 1500: loss 2.067643\n",
      "iteration 1200 / 1500: loss 2.076163\n",
      "iteration 1300 / 1500: loss 2.093530\n",
      "iteration 1400 / 1500: loss 2.071277\n",
      "iteration 0 / 1500: loss 782.934718\n",
      "iteration 100 / 1500: loss 6.407016\n",
      "iteration 200 / 1500: loss 2.077901\n",
      "iteration 300 / 1500: loss 2.098129\n",
      "iteration 400 / 1500: loss 2.065907\n",
      "iteration 500 / 1500: loss 2.033387\n",
      "iteration 600 / 1500: loss 2.101576\n",
      "iteration 700 / 1500: loss 2.052765\n",
      "iteration 800 / 1500: loss 2.103006\n",
      "iteration 900 / 1500: loss 2.087466\n",
      "iteration 1000 / 1500: loss 2.099855\n",
      "iteration 1100 / 1500: loss 2.049599\n",
      "iteration 1200 / 1500: loss 2.098658\n",
      "iteration 1300 / 1500: loss 2.114729\n",
      "iteration 1400 / 1500: loss 2.050356\n",
      "iteration 0 / 1500: loss 795.918248\n",
      "iteration 100 / 1500: loss 6.116835\n",
      "iteration 200 / 1500: loss 2.114014\n",
      "iteration 300 / 1500: loss 2.091077\n",
      "iteration 400 / 1500: loss 2.028170\n",
      "iteration 500 / 1500: loss 2.157874\n",
      "iteration 600 / 1500: loss 2.103860\n",
      "iteration 700 / 1500: loss 2.032451\n",
      "iteration 800 / 1500: loss 2.078096\n",
      "iteration 900 / 1500: loss 2.049460\n",
      "iteration 1000 / 1500: loss 2.123343\n",
      "iteration 1100 / 1500: loss 2.106107\n",
      "iteration 1200 / 1500: loss 2.081075\n",
      "iteration 1300 / 1500: loss 2.110900\n",
      "iteration 1400 / 1500: loss 2.112775\n",
      "iteration 0 / 1500: loss 810.493291\n",
      "iteration 100 / 1500: loss 5.750778\n",
      "iteration 200 / 1500: loss 2.129805\n",
      "iteration 300 / 1500: loss 2.183788\n",
      "iteration 400 / 1500: loss 2.041511\n",
      "iteration 500 / 1500: loss 2.097664\n",
      "iteration 600 / 1500: loss 2.129228\n",
      "iteration 700 / 1500: loss 2.122751\n",
      "iteration 800 / 1500: loss 2.136022\n",
      "iteration 900 / 1500: loss 2.106700\n",
      "iteration 1000 / 1500: loss 2.081613\n",
      "iteration 1100 / 1500: loss 2.111021\n",
      "iteration 1200 / 1500: loss 2.085492\n",
      "iteration 1300 / 1500: loss 2.075685\n",
      "iteration 1400 / 1500: loss 2.091196\n",
      "lr 1.000000e-07 reg 7.000000e+03 train accuracy: 0.305163 val accuracy: 0.321000\n",
      "lr 1.000000e-07 reg 8.000000e+03 train accuracy: 0.318735 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 9.000000e+03 train accuracy: 0.324184 val accuracy: 0.332000\n",
      "lr 1.000000e-07 reg 1.000000e+04 train accuracy: 0.335490 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 1.100000e+04 train accuracy: 0.341163 val accuracy: 0.358000\n",
      "lr 1.000000e-07 reg 1.200000e+04 train accuracy: 0.346306 val accuracy: 0.351000\n",
      "lr 1.000000e-07 reg 1.300000e+04 train accuracy: 0.346408 val accuracy: 0.360000\n",
      "lr 1.000000e-07 reg 4.700000e+04 train accuracy: 0.332551 val accuracy: 0.351000\n",
      "lr 1.000000e-07 reg 4.800000e+04 train accuracy: 0.324510 val accuracy: 0.340000\n",
      "lr 1.000000e-07 reg 4.900000e+04 train accuracy: 0.333286 val accuracy: 0.338000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.328918 val accuracy: 0.344000\n",
      "lr 1.000000e-07 reg 5.100000e+04 train accuracy: 0.330531 val accuracy: 0.343000\n",
      "lr 1.000000e-07 reg 5.200000e+04 train accuracy: 0.324429 val accuracy: 0.340000\n",
      "lr 1.000000e-07 reg 5.300000e+04 train accuracy: 0.327796 val accuracy: 0.347000\n",
      "lr 3.000000e-07 reg 7.000000e+03 train accuracy: 0.382755 val accuracy: 0.389000\n",
      "lr 3.000000e-07 reg 8.000000e+03 train accuracy: 0.378245 val accuracy: 0.391000\n",
      "lr 3.000000e-07 reg 9.000000e+03 train accuracy: 0.375041 val accuracy: 0.385000\n",
      "lr 3.000000e-07 reg 1.000000e+04 train accuracy: 0.370469 val accuracy: 0.392000\n",
      "lr 3.000000e-07 reg 1.100000e+04 train accuracy: 0.371510 val accuracy: 0.388000\n",
      "lr 3.000000e-07 reg 1.200000e+04 train accuracy: 0.363245 val accuracy: 0.366000\n",
      "lr 3.000000e-07 reg 1.300000e+04 train accuracy: 0.367490 val accuracy: 0.380000\n",
      "lr 3.000000e-07 reg 4.700000e+04 train accuracy: 0.334633 val accuracy: 0.343000\n",
      "lr 3.000000e-07 reg 4.800000e+04 train accuracy: 0.337143 val accuracy: 0.355000\n",
      "lr 3.000000e-07 reg 4.900000e+04 train accuracy: 0.325878 val accuracy: 0.337000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.328224 val accuracy: 0.339000\n",
      "lr 3.000000e-07 reg 5.100000e+04 train accuracy: 0.325816 val accuracy: 0.337000\n",
      "lr 3.000000e-07 reg 5.200000e+04 train accuracy: 0.325918 val accuracy: 0.339000\n",
      "lr 3.000000e-07 reg 5.300000e+04 train accuracy: 0.329878 val accuracy: 0.343000\n",
      "lr 5.000000e-07 reg 7.000000e+03 train accuracy: 0.381796 val accuracy: 0.389000\n",
      "lr 5.000000e-07 reg 8.000000e+03 train accuracy: 0.379633 val accuracy: 0.388000\n",
      "lr 5.000000e-07 reg 9.000000e+03 train accuracy: 0.368633 val accuracy: 0.372000\n",
      "lr 5.000000e-07 reg 1.000000e+04 train accuracy: 0.371878 val accuracy: 0.387000\n",
      "lr 5.000000e-07 reg 1.100000e+04 train accuracy: 0.371816 val accuracy: 0.395000\n",
      "lr 5.000000e-07 reg 1.200000e+04 train accuracy: 0.371898 val accuracy: 0.383000\n",
      "lr 5.000000e-07 reg 1.300000e+04 train accuracy: 0.369592 val accuracy: 0.378000\n",
      "lr 5.000000e-07 reg 4.700000e+04 train accuracy: 0.324592 val accuracy: 0.334000\n",
      "lr 5.000000e-07 reg 4.800000e+04 train accuracy: 0.324061 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 4.900000e+04 train accuracy: 0.323959 val accuracy: 0.328000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.326816 val accuracy: 0.339000\n",
      "lr 5.000000e-07 reg 5.100000e+04 train accuracy: 0.325673 val accuracy: 0.337000\n",
      "lr 5.000000e-07 reg 5.200000e+04 train accuracy: 0.327531 val accuracy: 0.341000\n",
      "lr 5.000000e-07 reg 5.300000e+04 train accuracy: 0.314531 val accuracy: 0.330000\n",
      "best validation accuracy achieved during cross-validation: 0.395000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs294_129.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 3e-7, 5e-7]\n",
    "#regularization_strengths = [5e4, 1e8]\n",
    "regularization_strengths =[(1+0.1*i)*1e4 for i in range(-3,4)] + [(5+0.1*i)*1e4 for i in range(-3,4)]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for lr in learning_rates:\n",
    "    for reg in regularization_strengths:\n",
    "        \n",
    "        # Train\n",
    "        softmax = Softmax()\n",
    "        softmax.train(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            learning_rate=lr, \n",
    "            reg=reg, \n",
    "            num_iters=1500, \n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Training accuracy\n",
    "        y_train_pred_cv = softmax.predict(X_train)\n",
    "        train_accuracy_cv = np.mean(y_train == y_train_pred_cv)\n",
    "        \n",
    "        # Validation accuracy\n",
    "        y_val_pred_cv = softmax.predict(X_val)\n",
    "        val_accuracy_cv = np.mean(y_val == y_val_pred_cv)\n",
    "        \n",
    "        if val_accuracy_cv > best_val:\n",
    "            best_val = val_accuracy_cv\n",
    "            best_softmax = softmax\n",
    "            \n",
    "        results[(lr, reg)] = (train_accuracy_cv, val_accuracy_cv)\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print 'lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy)\n",
    "    \n",
    "print 'best validation accuracy achieved during cross-validation: %f' % best_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.372000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print 'softmax on raw pixels final test set accuracy: %f' % (test_accuracy, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAF/CAYAAABQVS1eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsvXuwbNtV3jfGenb33udx7xUYSSDxCrYBEwRYBcSAMTZG\nMU9hYcCOCGBcDgSwkoCwDZYNQRHGgCEotkGE4i2jKBhjVwqqhBNMgiqgooghirGErAd6Id3HOWd3\n93rO/NF99/zNvr3P2Uu3+xxdne9Xdar69F69eq0151xr9vjmN4aHEEwIIYQQQlyO7F4fgBBCCCHE\nUwlNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGIC9+3kyd0/y93feq+P\nQwgRcfc3ufuf2/P+n3H310/c14+7+3ce7uiEEGYaW2b38eRpi5JcCfEUIITw6yGEP3mvj0PcXS6a\nTAtxr7nfJ09CJLh7fq+PQUxDbSbEU5+n2jj+gJ88bX+5fJu7/567v9fdf8zdqz3bvdjd3+DuN9z9\nd939i/G3r3L3f+vu3+vuD7v7G9398/D3q+7+Cnd/u7u/1d2/y939bp2jiLj7h7r7q9393e7+R+7+\nQ+7+ke7+Gnd/z/b9n3b3q/jMm9z9W939d8zslrt/wI+L93Oeuzted2X2fW3m7s9x99e5+2Pu/koz\nm927UxC7TB2b7v6TZvYsM/ul7X35v7u3Z3D/crux5e6f7+6/7e6PuPuvu/ufwt+e7u7/y7Zt3+ju\n34i/vcTdX+XuP+Xuj5rZV93ds3py3C8Pia80s79gZh9lZn/czL59zzZvMLP/LIRw1cz+gZn9tLv/\nMfz9uWb2ejN7yMy+18x+DH/7CTNrzewjzew52+/66wc+B3EHtpOef2Vmb7LNTfeZZvbK7Z9famYf\nYmZ/0sw+1Mz+/s7Hv9zMnmdm10MI4904XnEhF43XXZn9vM3MLDezX7DNWHzQzF5lZl96Nw5W3Jn3\nZWyGEF5oZm8xs88PIVwNIfyju3zYwszcvbQLxpa7f6JtnoVft/3bPzOzf+nu5TaA8Etm9ttm9nQz\n+xwz+2Z3/wvY/Rea2c+HEK6b2c/cnTM6DPfL5Ol/DCG8PYTwqJl9t21uzgkhhFeHEN61ff0qM/sP\ntpkwPc6bQwj/c9gUA/wJM3u6u3+wu3+wbW7gLwohrEMI7zGzf2xmX3HkcxJP5Lm2GaTfum2LNoTw\nf4UQ/iCE8JoQQh9CeK+Z/YCZfdbOZ39w20eau37UYpc7jtctbLNPNbMihPBDIYQhhPBqM/vNu3XA\n4o48mbGpKP695XZj62+Y2T8NIfxW2PBTZvb4ePzTZva0EMJ3bz/3H83sFbb50fM4vxFC+CUzs6fa\nvbe41wdwl3gbXr/ZNoM4wd1faGYvMrMP3751YmZPwybvfPxFCGG1VeVObROJKs3sHdv3fPvvLQc7\nenFZPsw2k9wkcrSd4P6gmX2GbdosN7OHdz77NhPvL9xxvO7Z7hlm9oc7f3/zIQ9KPCmezNgU95bb\nja1nm9lXQY5z2zwPn2Fmo5k9090fxt8yM/s17Ocp63i/XyJPH4bXzzazt/OP7v4sM/sRM/v6EMID\nIYQHzOz37HK/eN5qZmszeyiE8OD289dDCJ9woGMXl+etZvasPWuWXmqbgfxx2/DwX7Mntq2cl+8/\n3Ha8ArbZO2wjBZFnHfKgxJPifR2bGpf3ntuNrbeY2X+/ffY9/vw7DSH8c9u0+R/s/O1aCOELsJ+n\nbPveL5Onb3D3Z7r7g2b2dyxq7Y8P0hPbDOD3bBeefrWZffxldhxCeKeZ/YqZ/YC7X/ENH+nun3ng\ncxB35v+2zUB/mbsv3L1290+3zS/aW2Z2092faWbfci8PUtyRO43XffyGmfXu/o3uXrj78y2V3cW9\n5X0dm++0zVpSce+43dh6hZn9V+7+XDMzdz9x9//c3U9s0+Y3t8aOmbvn7v5x7v4p9+Y0Dsv9Mnn6\nWdtMcN5gm7VM3719P5iZhRBeb2bfZ2avtc1g/Tgz+/U77JMz5heaWWVm/69tQs6vss0CSHEX2UoC\nX2Bm/4ltfhG91cy+zDYGgE82s0dts4Dx1bsfvYuHKW5PsDuM1z2vLYTQmdnzzeyrzey9ZvYCe2I7\ni3vEkxibLzOz79i6nP+bu3fE4nFuN7ZCCK+zjTnqh7fy3O/b1jW3bfPPN7NPtI1R4N1m9qNmdtU+\nAPDN+ucPXNz9TWb2tSGEX73XxyKEEEKIpz73S+RJCCGEEOIg3A+Tpw/s0JoQQggh7iof8LKdEEII\nIcQhuR8iT0IIIYQQB+PoSTK/7sX/8jy0NfbD+fttF5OJZigDlxexNmCWxbkdI2Qj86yN+9+/qLRc\nGOM2I14P44DX3GcamSvyeMk8j8fK4+NHxiHut8ziMfGcDfvJ8X6WY0fYT8DxOfaZZ7FkX1XH1y//\nH77oIBl6v/2v/OXzL57N6/P3Z3UsIRYsXlOeY4+2yTFlz5j2xdPuWBT7+0VZxnMr6vn567ZDe/bx\nGvVDH98f2/jdcL77GI8jy+J38Rh4rJ7HYwhZ/N6APm5mlhXxnPohbtf3OCYc69jHbdYYI00bj/s7\nf/wVB2nPv/ltn3j+xfOTBY45tm3fd/EYmng87HccR4ZzHAKuBa4dsyQGbO95ef46xzgr0GGKMm7T\n4pqYpfeLfsT1HTpsFdu27zmm4vZZxj5cYnveL+LruszxOh53nuH80f/7Lr7/z172uwdpy+/54ued\nt2WO6zCin40D7hvo+1UVj/nKIvaD2SyO67bjNTTr2M1xP8rQVm2L/sJGx/jicRToIwPudzy+gKvF\neyvvO9xnjtchxGthZpajD7N/tmjntsX1w3Hzepwtl+evX/Ka1xykPZ/3lZ8Zx+YitgPvtRnGSF5h\nXCT3mdgGvIfmuC+V5f5pAPOZ9mM8X473Ap/NPPaDuo73EDOzpovXsV/HYxoH3EdwvyhwLyjxLAt4\nTvct7k1r3gtwP8bDeMD2y/UqboN+lOGcf/mVv3XbtlTkSQghhBBiAkePPAVjRGb/DC+7IPJiGX7R\n4CeH49dj8qufv26wnwq/Vjm7HfmLCdGJHO8zQmBmluNYHb9EesxeMQG3CjPoqsAvwpG/yhHdYDSE\np5NE4fALmLNmw7GG+L2HI55YVe2PcqXntT8SxF8SjCLt5kDE5UqvO35BGc6Zv4g6/OLI8Ms1Hxjl\nia/5yy3P8Kus4C/0+GsKu7F+5C+d9Bd6jl/ibENep5ZREu4Lv6Dabm2HpsCvw7yMrzOcZ49xNxrO\nje/jYoQRfRkRLEZDgsf2qxZxG14f/q5LgpOITs6zhRFu1zbxevWINgZGPXB/GfHL2jmAA9sstlNZ\nImLCyBP7ds7rEvc/lGl08hCcnFyLx4A+1yFaOCAiwbFSlYzy4fpijA9Neh9sL4jCZUmkC/dUXPfk\nPk1FAfeLVDnAeEfbsLsw+JnzWZHx9U5kGzvIcLNJIv7YF8d8KOK1WZwcPgZRIDJEpYH2p+SeiDHF\nCxwwjgZsw8+OzmcOxymUA9yvAq9pQLsa77/p+Qx8ZuHz3Gy9jmOkwjZFEdUFG/dHFUvn/Yj3Y/R5\n9LUixPZzNOzQpf38dijyJIQQQggxAU2ehBBCCCEmcHTZLlloiIWbXMSZOxaKYTo39AgPQqoZEH7j\n++O4P3TnYf9i68EYMqZGFF9mO6FeSomJdNNyQTT2lSx0T3aETRDexzEVRYmt4/4bLALscX0DQszl\nwNj4YVhhkd3i5ATHgEWJCHl3I485hkOdIXJIAwxVm5k5JIQuuY7xPNm/Vm1s56bBAkdc0xkkXDZI\nhTB2dUEYm+2RSElcJJ3tXPcLJNYBC7G5GHPAa65nDcPlw8mXZTaLbUgJusHCey6SNUgVlFVqtOfA\nxboYO5R5aQxIFv9DbhqwIrmDXJbKE6nMy3FUY2FtXWPMQvbp0G5dB2kv4DW+ry6wSHwG2ToxFcTj\nYVcr8L1cSH0oqipKG7MaMhyuLyWJDsdwMse1gnw9oi3HHQOOczkGlw7UsQ1ztPOAmyWl7JwmAadU\nhXs27t9cDM4aw1litGEf5H19Z1lATmMIDCmU83Lca6G2ZjifrD+8DMvF3ZQezXAt8HZiZMIfCj7i\nKZ1zjziXqoKkhvYo8Il22H9vpTmG95P0qM2M54a3S4syfIV+yz7C4V+UOAuccwcjCWXFIYv9v8a9\nPPB5PyGepMiTEEIIIcQENHkSQgghhJjA0WU7rnBPZmp0SiDs2zpkC8pWdCrRfJAYY7jyP9INF4RV\nsc8kbw01mR1pgC6bMTmQ+JkS4WGGgP2CXFWUG7hNmksnfhVDpSNlJZ5/noZND8EKDia+zooY9ue5\nU2obEj0jhmSzKn7Wy/jazJL8V5RhmcfkJuTANZQtKE820BlW7c/n5Fl0fdEpUu20//n2I48nfnHb\npm67MLR7P0PZg41LhxJzkjWQTA8FcyYNiQwTt3FIdfkMsgoj5ujjdKoyV1PiSEzylMX9cNxRbirY\n9znkUh08kXrKGe8d+yX/ALl5sHh92ReybP/vS8rTOfORJYZByr+UHg9f1cHRT7MsnvtsARkO8lIJ\nh2ByzOgHA+TSWbUjqeM6dv3+e0EN12a7Qv/lkGLeHlyXPskRhdxsSW49nnN8PcN9JCtxX65TBzLb\ntoTbNDjlLeQbQrMVyAtXHkG2q2e8F8LNyHt84kjDcSI3Gd3o7I9dT1mc+4/tPCbJufBdOIYs6fvM\ny5eOmwrutpySGdtwwWcol0gwuReOlbkDsWRjSK4XXbHxGFq649HeHMt3QpEnIYQQQogJaPIkhBBC\nCDGB48t2LIGCUCGTpjlC4HQKJG4jutAgB1CSYbiupzTAcCvCiSXCynST8Dh3g3iJHIZ0//NFdLtw\nE7oU6AgZIM8gOm6Z8VpAYqA0wpBm4qyh3HD4JJl0UCTHwIRuLGHCY0ZPy+dX4vbl6fnrMUmYaTay\n1AMcmWeQwpoifr5DiHoZopTQoMTCWRPP4erJ/u9m8jWeW4fry6SKPdxZfZ5KMizpkUF+SCrvoJOx\nlEwP18i6PXySTLugPeuaSQkxHpl8DgfNMictrksSuWe/oCySlDuKUsXIRLgsu5S8nzoQ2T8LuM8o\nRdGJ0zRMsApXHaTkAteCsiC1zQBJLpF8mLgvUOZL+/khqKroVKJLNSlbghtqfUFJJV7rxPFmab8u\nKYe18XWD0htNH8uWBLhiCyRPpbzedRck2ITEmOF50uPDlAirgo5KXPcdw2oJx2SBNu8RU8jgE6M6\nx64XssPLdjOUS8qTpK14DqKPe1IWiI45ynbxZQ7JvmDy1AueV9QsWZqHz9Oqiu00q3b7OBPS4l3u\nC8eU5UykjOUbcCkPDfsU+jwcn3ReJi76xHmJJUFKkimEEEIIcRw0eRJCCCGEmMDRZbsicdPE10xe\nVkJ6Suq5MYkZnBJM3pU4BS5wRqUVpBmqZUI4yis4hh3hjlJixlA8zy3sd1WxvhVjiDkSb1LO8SSE\nDtljDvcQwoysV3QEs51lSYJCurMQ0qUDotrvllwioegSCdey1KhmLa7dmtIQq8OXMXS9RKh/CcfJ\nUO2vDRUMddVahJwh/6zRv1aJY4oOObTTjvNmRGiZ9RNLfL5ropSU1h+jK+0YDYoEhZA9KLENIwcw\n5Cm6X9FwIwZP5xck7kM/4v5rhOorbNP2uD4YmyVrXlna30o4A5kQctlE11ffY0zRxYXbImWfpN4e\n2i+pbg/5JB2/2Etx+LbMStYI5P7jF5clpRPIUXCs8tBGjM2+ixKcWVqrzHnzg2zXLqPU3DZMpMsk\npExumKxfiNujTmeO2oH1HFId2p71Eks6tvN0KUMORxv7f1Kec4jtmTHpJ2T0ccf1eQjocu2xTKFH\nMtc6xw0TsjOTm/K+66zlCldZ2k9x/0bblHBbFnTkJZI15b/0Zl6gjyxhi+b4opNy6Lh8BRIgjq/g\nWEsSGGPpA93LOG6uaknqq17kzN+DIk9CCCGEEBPQ5EkIIYQQYgJHl+2YyIoJ8ZIsewyt5Vwpz9pD\n1MXweoBUxSR7qNFDlwnDs0yqydBlQUePXRySvUjCYx06OlboDkgkzOTC7JeAnLJd2B9+T1xMw34J\n88lAZ0UPKSXPojMkQyjV4LjokWyuwfVlqL5p0pBph/NpGJbOkXyvjfs96+P7Pdq2Zxgb7dk7Q/WQ\n5ODIylBHsIbjr3Jsz9prXeqKC+tb569PICWdwq1EZShJyggNpap3EogegBzJBJPEdRiDXUfHGMYa\nHDArNFvLsD9kuLGnHo3xhZMv4Fq8du3q+et6Fo/n5hlkizr2OzOz2QkcU5DIzzpKLBhHrNWX1LnE\ncTsdwqjBCZmMzrM84zKCeGyUbMMEaeCyDAOlGiwDSLpTPK8GiS0byMZGqR2yTU/d0dIEmiNkpZFV\nzHC9uqQGJWS7ZK8sGBm/u1lHyTBfx+O7/uCD8X1KamiDJHFjlcYKenwHT48ObmNt04HHh+tUHN7Z\nTCdsh2fcEuNogNx6gvqNlMUpESeuSiZw5bML16TFkhC6MCskoGXCzA4Jgtd9Wr8xSeKJPkYLYwcn\nHZeyDANkNS6VgVyePH9zPis5LvhMwCFQUr8gKe4+FHkSQgghhJiAJk9CCCGEEBO4C247rKBHSJfS\n1pjIU/GzXL3fMUnmSXTZMMzGcF3PU+M2CB+24/7kdkwU1vY7ifiYQI3J2/DdARITk2EyiedA511G\ntyHjx9gG8e0W8l/TUkqIG82PEEqu6xqvo2SyuBIllgwh2RbXag1lYERYed3HsOpjK2xkZitEz1sm\nZcR1X8M2cTbG15SbWAuvgBR80sMlRSchku/N8tjXThDsXUEKyhkabnfcdmvKx/H9eeICgguPWg/k\n6fU6vTYHAQdUz0/2btIwg2tiGUMoHUPNK7piMT6Q6I9yQI6xv0ByQzq12GY15PtyxwlLmXuELt72\nzI7HGluQAODiovt3gJTolPBQ45KXgrUvM8hzSR29IzTlyGTB7ILoTiuMrwYyWgspyPP44Tnk0sRR\nZ5YstWDduwFfvqLTGJJ1D6nek/qSvO6QP0vev+M2NyDnrSBDtsi8eHoaj/sE7jwzsxptziSpvF/w\neTTArTZwGYEffolEiWODKdQySFsByygytAEdhmVJpzmeUZC5evQFDqm+YN1Q1hdEYsySLjwuG0k7\nOZNlz2axHXKMTcrHA5ajNG10yOYXLJVhYuth2C/tDUwijfFIp/1tVuk8AUWehBBCCCEmoMmTEEII\nIcQEji7b5QgVjg1DhTFs5igUlCEU2a7oYorbzxlup3uOSdBYTI1xdWxfILzbIczPkHHYrW6Hvy0h\n6WXYrmItIoZZIYFQxuAC/xGyD2ubMcEZ7Vk0ISbuxOrwsl2JmlQni1gX7vTK9XhoOJ6bt87OX99a\nxeuwDLE9HlnH6/nes9Sh0cD1tA7xIq0gLSwhBa+ZfDHEY12vYkif9QKvINkoot5WIjHeCfpv4qMb\n4vWdI3y8sJ3rjn31DWTbEnIV5IqKjsmAMTKm8vEhqMr9iTFphGV9woA+mKR7RZK5WUnJOm5Twt0z\nrGIYfuhiHyloX6XM10R5JmMCzzZ+1szssVsI40POpbOV94URbTs7jf2ZrlJHXx0D+jC+e0jMWZD/\nIOfw1nSEprSipPMQyxEwPrhsoIDTku7K2QmSUGJMdO1Oksxm/36ZPLWjq5KORLocKZezFib0shLt\nQXnyFsZ1B+kxh8S0YH1MSxm7/a48Pgvo1hpxDxqK/cd9KIp5vPgzuAS59IX3MrpfS9SY4/OqQu24\nEnJpy3OhkxvbexuPpx0oo9FSyud72slLOuG5NIF168b4HWssTekpK1NSzym30WGKZzGTayPxJhOJ\n8gYxRYBV5EkIIYQQYgKaPAkhhBBCTODosh3VpqQG0IiV9R1fw6FBexKcXjlCiEkSNISDcyTJDAhL\nOtwaAUn/VpAS+pG1cdIaPVztz5pZAxwLMxwTHUQ81hEuM9ZGy3GN+gaJ6OhITBLWIRxaQyfZSWp3\nCGYImc6RALOELLpGWzaQqTo425breJw3bsbr1hnkVTNrIJkskdByOUTJoUXCzPWI9wfKR5Rk4/4d\nx33KoQAZuUcGtUeXj56/LujIQdR7lqe/RxZFlFNq1ICrECqeoZ/7ANdQz9pVh0+syCB1wzHIcVRS\n5t5fa3DgOGV9KlhXmMA1g8w3WBx3HV0vHNf47GoZt292pKQl2ryF5Fucwp1b7z+ONHnu/vqC7Ds9\nGx33iBxyBeX/EklVh517yiEoklpodGzi/pDU76PzmclYoS/CXTju6Bkd5Tm455ZYXtHAYTUwiSHu\n5UldQOyfwyhwSOG6s/Yekzs6JMkR934mcDVLa/rN0BccnxkgGXVMhov7zjGSZJY1pTS4YgOc2ax9\nCal2gBxZUS/mPQtJRWd0OSbucNadZHtjuQueUUlJxZDKdgWWfGSsC4kxXzOJKe797M4FpEQ6O5mc\nlYlBe9S5GyAXVovYR5oVnuP95e+zijwJIYQQQkxAkychhBBCiAkcv7YdpmelU+pgUrcYTmsQBnS4\nBuqK8hwS5THUh7DcenUz7gdy1hphSahHtkYIN8BBwDCmmdkMLrYSIe66pJ4HdxecIrMcDpcmhgpb\nuEYCHHZJNj1IOHScJPm9aBkbolRxKJI6Qfje1S0mqIvbFKh5lyOsGhD2neXYJk+PuYCsWlUxEWfp\ncbslXG+O1x0ad4GQfOKKROcsGa1tUQstj9e9GOKxepKcFKHrMZVk6orOPZw3mqrOmDQQ8gPGy6JO\nJc1D0EFKCWg31nwMGWudJZrn+cueYXyEvVnPivsfsX8mTF1B/jnBeK+wTQeXV9emGe1Yn6+HDHn2\nWGyT+QNX4vHVOGfIAQWcYY5+O0Km53jsA6WduEnBxLmUjsf0uA8C6wgyoXBJSRXnhWUTdD4vIWE4\natOddank1TApJ677GtJ0myhPrIsIVx0TbEJWa9GPWJMsK3nPvRa/gJLUPF6LFd5nbUqz9JnS856P\nZ0EOaZ/1EnvIUpS9DgWfLbRndh3GJuvCoW8GSJizBeq/XZDMM09qvFKSi7I4k/dew/IN1ssbnW7O\nnWvCZQdoEx4T64vSDZiYcOnsxNhM+hTmBy2eoZRjeXyJyt1ffrmLIk9CCCGEEBPQ5EkIIYQQYgJH\nl+2YmIv1g5BvLjkI1tlhGJer9xlaTFb1ZwxFw+m1jO+vcAxWoZ4XXHh5clXS+SVX9VOqqxC6HVn7\nhwnoaNVjbjGaqiCB5MZrgZCx7w/FU8FkUsJDkdMPA/vN+gyyHRxzVRZlyuu4PhkS8T1URjmuHdPu\n+O5bcO5VMUR/WsaknCuP37HG52dG6RRSKxxHGdw6TomUCd366O66Pn8o7gd958SQwDWkDrBrNZJy\nVpAQcn53/I4C/assIWOUh5ftKBEaE0PmdLQgySD6YMAgoTTdr1gzCnXS4GYzjBu63EbIdo89EpNQ\nlhjvDeqzrXekpBb3ghXcRB2Oj7J4FWLfqSG9sa5YDqknQHoYICuUOWumQcaw/csUsuwYWTJx/8I9\ngXXhekh1lPZuoW5iC7cntfmmT6VGlnAcIXn1rBfH+x3rjkKGLWaxrzHhIh3IVFIq1EWr4QRtGyx9\nwNKKkclZd26JLdxadNJRYSpxnXqnK41a0uHddpR5WZ8tx/OUEqYPfD7y0Diu8T42onu7YJpILi1B\nUlguleEyiA5SOWvnmaXOeSarZK1Y1sYrZrEfpe0Uj4muukDza8blCHhNF/1IKRgypEu2E0IIIYQ4\nCpo8CSGEEEJM4OiynWE1PWuvGcLAGWrUzKv4/s0myhnLFV1ccZsany2QiC4gsdiIxGJJ4kaEJavT\n6KRi0rjdYjdMzEapjoniFpAlatrSEBJnPb8SYfx2jNvM4AZics8GYc8Boc4aFq6iOLxsN5vBDYfT\nYpjYcGxs7jmSXJ4uHozvnzzt/PXZkHbHCtLbDdSq6/IomXVlfJ3V8fWHwGHZ0t2EELW30EuhI/sM\njiO4Fq8hweJVHOoC7Tf3tD7f1Sr+7UoBx2QTE242Szpcbp2/Zum5Oj+8bDcaHS2U1+M2TPRIlWzA\nraNAGL/ANh2klzWj4dwRlXmMoTWSYfZnqCNHF90qlb96JMbMr8RadTnGNiUWKlF0ZS2QZNFZPwvu\npnxA0j9oBpT2cgwAlhvLw+F/s7Yt5MKkzTAOIA8PfRxbS5zXrSZe3wxutKZNK8MxaS8l3wa3nQH3\nwRJyG2shDjldUvgCtEeLftFR5oFNqsQ+x8QtinPYKSp448Zj8TNIylihjxQ5l4ggkWoXj2NpqVR/\nCFq6vOnARZ/i0gzKcyPcgh32w+ddAbfkHPJfD+f3rRuPxGPAc2k4oxQWN2HSyrJOndMZnlMD9kX5\nuJzFcVomLsx4DuyHLR/O2J5SbQUJl32BCT3pCh7a1JF5OxR5EkIIIYSYgCZPQgghhBATOLps1/cx\nzEbnAl0DQ3cTn2CSvfjuuomhe4ckNSJhV4YV+pT2AkLDC9SAarESvw2U1OI+F/NULgmoSZejnpAj\n0Vy32l9jjknWClwLJt+jI6Ao94drkwJ7iHUzRyZrHR2KDA3SI1khv6vo4HiDG2JeRylkXsVEhfPZ\nA+evz8bUteKQHK71sQ3XkGfaKsozGSS8Bv2I9ekCwtiUJQLk2BmkmhqJAku8P4PMR9nu6k5u0hlk\nvHKMfXgF55Nlsf93uAbLdZQDmgk1ly4LDTF0N41wmNFt18EBROUph3ydV6gviOu+Rjg8QGIyJMUN\nN6Nk2Z1Bsn/kRjweSK1ny1RKGlA/q2YiVpxo8UB0bTrO59YaYxOvKYW3/K2ZJF6FYwya54jz7zHe\ns4LuvMOAknrWsb8nDkE4o9CdbmAst7j3lZBFxjI9Zk8STMb3WxxIjzHIRJoVrl2Le0cO2YZG0BJS\nYtPuv74OK9liHvsgr8tqCSehmbU476QsG54dzpqHAy2GcCLuJGs9BC2eJwWdynyu8SKhj3sW9r7f\nYBnMCn28oXsb98H1Mt5/8pEJYvHcw/XlZCLv0muSPL7oYMTzMccSnwAZkitQymQcoW4hk2fCCR6o\nK9JFXULbCUygAAAgAElEQVRSLyn5XT6epMiTEEIIIcQENHkSQgghhJjA0WU7ylCM8dUIlTnCrHQ3\nlJjblaglldWUrVB7ig42hFtZhyiDhHf9FDIPwqQ9Qt2lp/JXARknSxKo4fjwmQFh0CRcSUtTItXh\nbUg7HeLsBZIY1jUdf1EWateppHEIBiQQ61mDELYl71n3CKHnUyZMhBsR8sroqTTwQXCYPVTHv531\ncNacxCSboYphfzq9GLldr+CMCbymcHrg/RxtkKOdKoSAc0iBw8NRYjIza5ABtR/jd/cIfTfreP1W\nkHzHAte1OLzbLqkZxsSYPDfE25lAj66nABk5L+J1rKBy9JDFz27F67BexT7bQ6prbsbtG9QppOx6\n1qbOxmYF6RUSwAlckhWce9U8aqwjknv2j0UZ9TTAzcnbjtE9BPkIMsnIOocYL3l3eEmdEmmDRMMF\npA1Kh+uRTkgkvMV9JsN9sKp3nLALjFXIWQH3wSEgKSf61IjvpgO7Z+JVDNqRDjN8b8eEqbgHVeMF\nSRx3kln2rBFKuQbHESCZDS3uWxUlxsPHIFguj88vlqdzOtgauIXpKHYu/UDNtz729xXGTc46b7g+\nLRIhF3imsSYoa9QmmUZ3vjtZdYLlHD3cgAFt7pgrJImm8X6RUfLDPSupCYpjYLJRXKN+N5PqbVDk\nSQghhBBiApo8CSGEEEJM4PhuuzaG4nPWdIJ8xhpbixmTncXwY2UI71GSgwukgROn7+n04DZRMmib\nGJ7v4SboEPZ+bEhdAxUSLi7mMXQ7R42mgvX84CbpKSXBQeIIg3I6SzcUHRQBck7ijEK4dhiPOy/u\ncB3yAc4juO0YAh0KvoaMWsTjX6CWm5mZI7zfo21HtE+5iNLLfAZpAHX1GkgRyG1oPSSgoqDLCElL\nb8Chs4bjcxWdYcM6Jtvr1qlst4LbtM7ZhvEcOibJhEulRqK5xa6N7wBQ6qlrOlSYfBCyCmtJoaNm\nGIMjpNaAZJgB38UkjgMSTK6RJPWsg9ML+2QtrHxOj5RZjftIgaSMI8L1qzXqdd2K7ZlZdG2WGKeU\nf+cVXYWQnrrYR3LcLwq0t6MPJg6gAzFABg44356OYtx+z9Z0LaI2JeQcnqPtOgRpKEZSUSYcDHTu\nzeFag3zokIbyeZRIR9Sa5AqHnIlQISUGXOsO9z6n89DTx90AeT7DcfT03tEZinpozucClpQcigyJ\nRwfUOM3Qx1nuMnM6oeP2bYu2hduuw2vHvTwxFEJGczxPeV8OuC9XuA+UO8/NHDumoOd4lnFc9Kt4\nfCXu5cxumWF+4JBaWVOxrNFmbH9kdqbsziS8d0KRJyGEEEKICWjyJIQQQggxAU2ehBBCCCEmcPQ1\nTwO01aGEVR/rYWj/p1FwYIoBWi6ZPRqaLjMgD/R6Qn7NsObp7CxqujdYfHS8eE1CwNqFB6/FTNnr\ns6j1l7BZzqDFFtBiwwWZ11usE8mg158gnUNdxfUvRb6/KOngqeZ8COaLmBagvYG1Yyscw5qpB1CU\ns4nHc5bF656FuHaonqc2UWbWZdvm0OizW5z/o5go9O0G61aSBLIoMtljTVmDdXpZF48vuxXXM/U3\nY9HM9TqunQtjqpn3PNY51iXAGt8ssQ6HVuETWLfL1GZ9CJI1clgbU2G9kCNjODPMJ6uN8rgNC3IP\n7I/4nVZhLdc6j+NujXUnHRqqhJ25RBt7SO3QBdbV0ALNSgLMvu1YO3dSx+s7gwWaxVczjKkK7ZEj\nhUeBtR0FU3hgfd04Hn5scm3TiNc90n/3GI9rpE7g4RRYSMNis+UM607MLEfB1YHZo3nb9fiZCuvF\nkmKt6INVhfVyI/pgQKFm3BNGpP5osVaFt77a+V3p2qQaGc0D2qrB6xbpSZh5ohr2r6s6FEzxU8Ju\nPyL9Q8+1ssy8jbVATC+T7BNrjkusZcyYIb7j2keMrZZjgs8rrLsb0rHJJbihYHFjrJ1E+2dYzxhQ\nVXvAGswa66P5fs+0CMwezkwKTBuElCdLFCS/E4o8CSGEEEJMQJMnIYQQQogJ3IXCwLAyXmB1NqQe\nWCP8ypAjM5a26xhaa41WZxQxxf5pN+6QkqBFKJ1ZvikRNjvWRdqvH3uMtmSG+uP2D1yJhUhPT6IV\nlxlUW4Q7mdX1BCH0GqHuHFICZb4GIdflThHMQ1DN4vEXs3gMZ++FpRXW3qaPYfWbN+P710+Qkfta\n3M+VNg2rMwNwi7jvANny1iqe5/rt7zx/jTziiaxQQnrKKLEgfLxcRnkurKNsVzHtBvpRgyzZQ59m\nvV7xMwgnD0M87oAC0MMMfarBeMkPn6qgg3RTziA9UapC2JsFNCnPscgs3zeMnUCrM+zGtBWz0GcB\nmbpiYW/qruNO9v8ZrfFRklnRWo32Z9qDgikGIHvB6Ww1ZQVmocfYTyonrJg+gGsHLp/F+LKwOC2y\nPBiTaK+Z1Z63tQwWc2Rjz/E6y1LZOMsgmVC2RLbtCjJ1iZviDBIpr+PAJQuUeXHv6ygrsfnxqAho\nb9anDbaT2gLSbkAqlfUZ+i36tjMFBPtUc/hUBSzUXWFJQYVKA0nKC7zOKmT/R9Fqw/hIri+fxRib\nc7wucF/vx7hMwTCuA2W7PI3LMPs4Etony05mV+KYdaShWCOdTQ5pfnYar8US46tgShFW4GDfwaWj\nHM+lNXdCkSchhBBCiAlo8iSEEEIIMYGjy3bjQBkDhTjxLmrDWkeljmFDhMxHhAc7OCPoYaHzbEVH\nHkL9A+wTlM76gSvx05BshphjEyg5xG2c8iSzl9LpkxTBjJ8tEaKlfOIIK/dJIU64DCBDdjtFUw+B\ns1gjMg7z2FpkBj67GSUrFkkNYzz3E8grYUyv9Rrh8B6umeIkSqHMbjyguHPB0DD7EUL3HWSljiFn\nuOcGZBJfIePuCR1ZiO2zDczMHn3k4bhfHBOzG4cZHCTIoDznOZdRMj0UdJ41SD8dMCBLZIMPGWX3\nCMcj64GiK5vjD2tk+Q6Q4Qpk6Q8YgzO6viCd0I1pZpYjXD/g1lYlUhTcg3CQUXpjcVQWgK4w1nIM\nWhafpcyXOIyw/248vKTeQFYZcWzMFt/yRovOOEeBZGbqrtEe9Tx12/E76DZkVYQF+uxsjmUHxmzV\n8XWTVHnANiy8i1OocA/KkIWeabILjKG8TrOkJxIY9tt2UbYfcV1zLOdo4ZYNR3DbzWZ0J8INhy4/\nYoxQUuTSD4dEWp3Ee+16jEsNSkjtPc+XS1HglB8r3nPR7wZkLd/J5s5+yELKI8bUwKoVkM/owhyp\nvNLpx2LmeP7mkA9bFufG9rzWXaUM40IIIYQQR0GTJyGEEEKICRxdtqtQuLbMGQJlqDO+ZiHSHJIO\nHSrrWzE8uIQkN1zk3IEUMiBp3GoJ2QayRYuQcdekYbwMss8Czp0a8foZ3IM5CjyOkAwX2KbCfgpc\niyT8WrDYMJM+MkMdQquWykeHoEQY3nFePdp1hbj6mklBcZwd3j+DVNf16THfWkbJrKNECgfbCdyM\nJY4pIMHqABcmDVoDXHIj5NUK13fw2P5rOOSWkG9HJKt79BacKGb2Xvy/PoVEeUHC1Axx6ZOrD5y/\nvv7AQ3ZowgWJFQdI4SXC6pQJesqwuL4srOmQT5C3L0kw6ZDOsjnGHbYveWyQS/L6YgeY5ZA8Ieex\nYLAjyd4ciQhnGGs19rOA+zXnuMN1GRo4L+HuGZKlBod3Z61QSDXLqR1C2oHsNIdjlbJQh4YqkPx0\nPkvdnsndO3EoQfZDeyxwHR2D0H2/VLNEP8qK/Us2CshwBc6NNjyHJJVZ2l9ySH0jkvjO6zhOexTl\nHRs+F1io/PBJT08h5Wco2s02vGgZQIFzxmPQejjPbI32wDORiUO9obMRSyjwDFyhK4fkvrHjWmOx\ncUj1TCIckLTWV3Szop1L9oW4TQ2HIdfBdCjancGRmGOMO4+tSB2Zt0ORJyGEEEKICWjyJIQQQggx\ngaPLdqGPYbMCYVy6NwpIXh1D/QjRMf44w5xvQZcEoqdMtjlDiJr1cxiKHOGkYg67bCeMVyLcdwoH\nSY3Q9xxJ3ZiAi7WFshBDkSdI/JW485pu7/uU+Sh1OeU82lIORAUZte2jpPboGRxpcPQEhMUpi/7h\no9GBtqYzxlLXSoAclqMvdOvYp27CDceabD3C2JQwKSUN6yW2j99bw6ExQLZt0F8C2rWHe+zhG6ls\nd6OJ31EUrB8HWbmAC3N2Gt8/iedz7cHDy3Yc/h7gpKQewNp8OOcTyFwDwvjLW0hyGyiFoJ6VI8kp\n7g8+j9d9tcY4oDZAp9aODDPCuZUjqeN8Eb+PyfeymsktkZy2gqMP8iSNlAGyBO8QWfC92zBJYN8d\n3p11hsSOGdyJp5DemLewh6xNp1mF7UvcrwtLnWo52jODDEO1hskQvYe7qWTNO0hAIUqeAXJLjx1R\nDnJKypBweH0HSEHZTqhgnsib+A5IjDmTZyI5s0OeZELLQ8FlLTlkOJh8E8mLy0M4KkZIb3Qdn57C\nvdtB5oMTmve+rkSNWsj0OcbmGRzefZtKmZ5Yb+FYN0p92AbjZWF00vGZC7cl+vzATog2LyDTcxlM\nk9SsvLykrsiTEEIIIcQENHkSQgghhJjA0WW7Am47hmgXc9SJgmsG+eySJJkUoUrEz+cLJDqDfELJ\nwCGXUBmaw/UzvxZdWz3CsO2OM4YhatZDq+HoKXGeniQBi/tdQ5IqOiRJRGy9gpxXIWFZBUfieMYq\nbkhWNx7e0TM7uXr+2vP3nr/umYgso9QY22mF1yOTMDYIye6YVjImVkPyTdZSO6Oboo3XaETSOEqY\nJTTZBnKjQTrrIIsyG+QKbcakn0skUl1ZehJrtLk1lLAhYyBh23XIxBnC0qfXr9uhWa/iNS0gw9EN\nM7DGFuToumC9sbjPkVIIXJiG9+nCHFbx/WoBKR/J+lqDkwxuxNk8TRzqBSSnk/j69OoVHB+OFVLH\n6RxjELJdBdlmYAZQOHecUiLeL5mQFf2gaS6fiO+yMP8lTssGus2YVHBgslFIqkx+Cyk3G9Pf2VXY\nf49z9J0Mzr0c16JCncaK93hIOy3NU7jfc/8cabxnjxCuQuLCS07BeoznkklSeQF7SNtM/IhslUW5\n4yw7AGmy5Pi6Qc1SqHZJ0kf2077dX6dvXsexk/N5hbFc4F7E5TRWYzkFnr/lAHe8pdekw7U2LE3o\ncyYqxbMg53OTSTzhbK3xfMj5HKF2HF+yHmHP2qLoF/2E5NKKPAkhhBBCTECTJyGEEEKICRy/tt0Y\nw4ZMJphBPilhIWDiM4a6b0CS84zJKRHqRWjxhK4ahPRYF67Oo1RnTOII50bbRMnALHXisZ5QibBp\nSJJuwQWBuloV3GMFagVVCJVW+LKCzhKEZSmrdHAute3h62edXI3Xqz6Nodche8/569W4X9oaqMkh\n6dsN1ENa34KMZqnDMMc8P6OEeRKPIzMkUGPiQshqizk+u4ArMoNLENe9Q2K8R5fRSdeijt4SiRtv\nLCmjmrWQHCokoGOdNDo/mBi2XuDcyrS22CHok6SkSJQH6aZEgkLWEmPfp5HGILfVrN+YJJWML/PT\n2KfGLPbZRRalnb6GZAt3ZVak1ySHq/YECUlPTlBj7Vq8piNlIoTxKb3x1yXHJsdgSIpzsi4ma/5R\nUreDQzdfSGrb7W/XGZcZYBkA70v9BclJzdJlEeUCbjuMnTmce7MZHXZIeggZrlkiASo9Y+hHI+5x\nXUfHIBxTeD60lPN2kvCyzik7MWsVUqkdIHUywSbr8B2KnBpjYHvG888hneZwRrINBvSFEstjSqyP\nqRLpDLVS15D8VpDFFuhHFE9Zf3Wn3p8bXJ9w+jmSWzrkfOfSCdQnLCHnsX4pnaQZHZnU7ViDEf1i\nDRk9G+S2E0IIIYQ4Cpo8CSGEEEJM4OiyXQd5Y3UWk6CtljF8zrDsgGRlnTH8xkRhcBbg/bpmiA4v\nERoeB4aG6SSCVMHkefWONIAwJRPiMRlbjjArXUmzRQxXFgg/0lmQ082H73LWakO4eoTbzCFzZeHw\noeTZaXTbFZCXEOm1sxGJ0hC6HVsmCGUbI0leG/uHmVlDxxWSnrK+0UlS2i/KNkntKTj1HqhiG8yR\nDC/DtVuh/W7CkfaeWzfid8GW0mD/ZyGVSx3OrbyI1+BWz2SPkMBmOKaK7p7D/86hjOEIY/ereA5z\nyOgZJMi+pTyLRkA7VaiHxv5uTTzfRR23aSB/rJEkM0MIv4LDjvcKM7P5jO5UyLxoW8c5V0j02CNL\n6giH7Qoh/YpLASipw1U2wgLVNrQhxpd1dXgJNkAG5jIIpwsL465kvTDWAYTkNeLePXapnEGnV8/l\nCzP0ZSQkpvHSIbHRDFfgcZTBJUj53lGntEWy3IC+WUNqtoHyVJpUteByDvSLAWOTpmXKeXTntUdI\nSMzlIj3ug1yCwvqijj6YoXG6geMRyZjRIZkwta6ZIBTPLjiZc0iBjiUYGfKoNuu0v+Q4puoUiaav\nIoEt6zBCwquw1ILPZibXztnBIMHmiRM2bkJJPSRy7uVrwiryJIQQQggxAU2ehBBCCCEmcHTZbgXX\nV4kkgatVdCUFhOjGjLIFa9Gw9hbr4cTvKhCipszjiA23SDLGYOtsHmXEGskzxyyVBmiVYSibIcES\nn68Q+iwR9s2xn54SU2LFgcsiyfaFkCNlO4Ros/EYst0D56/pvJtfQdKzd73r/PU6wCWF0DCTByJ6\naoOnoV5nWBbXdMB1aVm3LkBKc0ibSNQ6ttExV0JhY73AHKHxG6soJS6N0kD8LFtsBhlqc1DxZaDc\nzBp7GbeBNMCah5BlDkUHZ2CzjDIsZZwrkGcpSVGS7eBCMiaVhUGL7hnKCiXOC2pJIu3OMYYKyCW2\nI8PMTlDDEn2HyT1HXPce7q6CSQAhgRhr1TUY+5AG6GjKuVyA+4QsSnn9UFCaDlz6kNSOjNcuQBZj\naTZKRHQNZzu/s+l+ZQ00LpHoGowp3B8D5Xy4MJN+wSUR2L6i9Bh4H0F7QBYskGCREvTmy+N+l+gL\n/L4sqRTH6xq3b4/gthuZVBhLMLKMfRkSdMlxhPYo0YZ4WNJhOWDMMn1riWUDp9dQNxRSXb9Gw+J5\nPd5M5a8Mnez0etzuwafFpSCsf5o4QFHzktdlCHSAUkan6zpu32D/dNh1WIIwtJdPYKvIkxBCCCHE\nBDR5EkIIIYSYwNFlu7bdHx5r4BhzhD0ZDs8gYc2wlL9IEgzCbTdAGkAofYDMtVhgdT8cQHyfSRLD\nkEoDdOKs6SBj4kaELzPWSWJIH9HOxGWAUHkiN0F6DDgGvl7DfbJeXz7Z12Up4cRZIDnlHEnTihLh\n/LPEqnIOnRQjZKpVm4a/k0SqdH3h2q0Rol4+BocKwsRMoMbwPsrZWUlpB0LcGlJzDudcj3YdIVWU\nO04qyrADQsgZJOaTkyiN8ThyJgfcqRV1CAZc72ENOauKx3x2I0p71RzXiG4oNltPfYayFd128Tp0\ndF7h9RzjnX2cLrqyZi2tVDIyHF8NmTg5vA5SGmTlrNp/bkx0OaDfrdvY7yj5rm7Fa+c9XKirwyew\nHZiQNmDpA+4bXELA5JQjLkqD+zUTNSbOT0uTb5aQ3uh0K3DduU3GBLaQFfl86NE2dcZkq5Dz4IQu\nkQBxwPOEyx2cjW+pLGmQngPcowHfTedai7Hj+eFjEINhSQg0TzoPB8iWrAtX4p5aYBlBjX4NVczS\nkn1wz+Gass5djeUE6yUk2BLP2SxdZjDi+s4WWL5S4X6cJLaO75+cwmFJ6RwJaXOu32FfQH/usZSH\nUmUIdA5ffmwq8iSEEEIIMQFNnoQQQgghJnB02S5j0kdIOmFkQjxII5BnEHm3fmSCOrpbUHuLdXL6\nGKIOCFdXgccDqa1GaBBh336nEBUjv/OSx8rEavg8Qv2UPfqBSbrgpkj0PLibEJbv1pQM4usV5ICb\ny7RO3CFg0HuO0O0cshNrBPZoYya2pPOKYtT8+pXk+5L6SOhHGeTWvmGInh+OL0f4KtkXBmb640iA\npOaIaZ+iRtpihg8g/O87ySw7hIeHka6ZuM3pdez3Wnyd1ZR/U/n4EAxMPpi4OZEcsaG7DUlrE9kG\nievoWqSNsI37nCVyQ9zP2QrtxDFBeRX7L3fHJqTqAedDabDjznAfccgkY8t+gWPFd7XrKMm1XXxN\nGWp5E2MQko91h5fU6SimIzjDeHQmwyzZBlhCwbOEa893EpIOuBHSGTWjA5LXfQnplUk8Ewcy9lPR\nLbn/ftEsMcjhrmWiYdbX7Ndpfb4Aua0uo7xV4bs7SENMsEzZMysPH4PgM44Os5YSNu4JSZk+yrO4\nYAPqiLZISFxAaqUTlGOoQG1N1qv1AvJlSSkzddvlOZ4FNZ3QcezM5khynCyPQU1cdM8smb1wmQ6c\np7iPcM7BOruO993Te8rtUORJCCGEEGICmjwJIYQQQkzg6LKdJ2FD1ipD2MzpAmDolsmu6EhDgskL\nVsczyV5AsLdGiDWnUw+hYYY6V30aYqd7juFaLNi3rqUrBxLeKoZNGUJkYj3KeZRVAkKRHcLP62Xc\nZwdpxMfL1+i5LA3CpwXk1evXY8LMhx58MB5bE4+ngeNxdgX15ZCctN251sszJFWF641OzTVdRgzd\nsqYRvjtH47ZogwrJ8Gaz2O9meZQkZ5AqF5Aq53C07AZ9mbAuw/FVSPp55UpMFHf9oYfiNgvUDwyH\nd9uxPp9DkrARkjf63dhQzoQ8AwdURrfowP6LsD2T2PGC4Z4wrGObFQWclvgA62WZ7bhW8Xr0eG7z\nE7jBIB/1iYsp7pOye2b8bpwbnGEdliCMSMQ3YGyGLpWPDgETY2ZoG9bBpERazKMMU80wbuBI6uKt\nJZGpzMx6LE3oINE4nNA57uu8r/VPGCXb44B8VEFuHHAvO7sZ5abmLF7HDN8bcGwDazD26T0x4DtG\nJqGFNkS3ZUYZ0yirpf3wEIwYdy0SIbOmpEHWL+jIC5Qz8YjHLSRxy2L8tuizfD5W2P+AizLSpUpZ\nv0zbOEkeC6kvOM6TLkwsHejgzmUd2JJJtFlTEi74sxWfj3D74zxHjp0J4SRFnoQQQgghJqDJkxBC\nCCHEBI4u21G2alHnLmvgCEAIlIkRe0ztxg51jIzuJoQKfb+zhFHVnM4gSAwBrjXW4Sk8DcmWiOvl\n+O41Qvc5wtKsOcUEXwbJqGMiRYSWnUn5EMZsUBfw1qOPxmM4iyFtJvE7FHRDdXDbVEhWd/3BWP/u\nFtxPDaTGq1evn7+eIdnmescN09uN+H247ushnqcz0yW0U0arGd4tEepGySSrIL3N4YqcI3nqAjLa\nFTjvaoaP8zQ5XOJ8gpPjyiJes6uoE/jQ06LseXoKOTBc3gVyWXI6q1gPC30tG+K5BSYxZSJZhuSN\njjy83zG8zySUkK8h7RSQVKq8wjZxn2O/457CNXJ+OZpk6CC7U3qBZNBiDPaspQUpuIE811IagCRH\nyYwyz265zMOA+xJddb4/MWbu+++5GeRkuvCqIu3XJa4L75A1XLWsF8lrGkbK81hSUUV5toHTtoWE\nS7kww72cEmE7oH4p76c7sQImbqSuxKHGfjSH1Ekn2m5NzkOQyOWJzEuHLGRHrhsZuGRhv7uctUI9\nx2fpZsM45d2HbkQmYR1xrapxp7/gftwHLi+BlJy0D+vcxXc947MVkizOeQ35v4X23OD9Dq9HfC+T\nF98JRZ6EEEIIISagyZMQQgghxASOLtsxtNbAfVWghhelMMoeA+Us1hJDDJFJ+Ypqv4uHTozEAYON\nEhcD5YYhdWj0idy2vybUyBpmSd06fgWT0cEdAsdZD4dOS+caEvRxeyZT8yNIA0k9Qsy7Z5DtHnwo\nyk4ZQvgDa0c5pVaElXfqZ7Hu3clplPdO4dZjGL+FU4g1oJJkqEggl+P4Zni9mCEBKJOBzuJ50gla\nsy/js2ZmFRIIUvk4gQRwMoty4LWrMVHorOK+Du/oGRq429B/W9wWssDzT+Ln8cjgTiqYeBDy0UCJ\nnH0BUmC3isfDoH/TRJm2hcxT7uhfAxyDzM+ZIWFuDmn4zJnUDzUZ8R1d4lrFsbKvQcIecT50Hp6g\nv/RHGJtFvj9pa08HE12qKzqb4kfZl2vWjtv5mZ1BF2dNskQ+g+tpjcS+A6SXErJilkGew3E3kO1w\n2ZNtAtxgzuSROAY+f8zMPMN3437Ww03GPL0dx0giAR3e2TyrIY3BhciHSA45u2QiUcrozJ3Kmm8j\npHkONjyLmdR3RBLogGc0HXkhwz6RMNPMzJmslbIoHdJoXC6JCWgPuh+5DKiHPDvy3sTPMlkyDoLP\n5WJ32cVtUORJCCGEEGICmjwJIYQQQkzgLiTJpDwVQ52BYc8c7ggmj4SUkiOsznAtXQM13h9pAcJn\nOyRbZN0n7idRA3bUEkpyTKw3cvU+ziEkSQMhE+D4Brgp+oYJ0fA+5Tl8F90ODDmGCxLRPRlaHiec\ngDWcZx/8IU8/f331QbRxT5lgv/zBxGVmZqcdat3hPJlstaG0ievS41rTSZWjzQu0+XwWnW0nkOdK\naG2UNCjzURaczxFiN7MaMh4i3FYmdbWY7C6+7ujgPIJFi9JrGDG+IIWuQ5TMQrdfGvEsnmOP4xxY\nw45JMvG9a9RjHC6oKdljmwIh+dmOzMufggNdu5D9WHuQtc2cjcNzwO4p54wX1IArnE4kOoPYZw/v\nzmJyvxx9toOccYaEuu2AZINQY5ngl9c3q9J+zUSXHVzEw2NxSQGlc0pbHL9lFa/jmu5cSMqsfTri\nftqhv1A+onSYI8GqtenNvIGkx2SPvJhrSo8r1HxM3IOHl9RL1v+jW5RWwKSGH/pgyefafjkyMZUx\nKSi2YUJK1qjls4jPQNZfHS2V7Qbcy5KlOS2lVDq497s+LelTkILRp/jsH5Nadeh3xX6ZO/PLt6Ui\nT0IIIYQQE9DkSQghhBBiAkeX7XKEBOk+GZAEzBC5G+CGyRNnVDxUyj5cxd9Va7y/f17YQc5h7JKO\nMT7Cqx8AACAASURBVH7Wd5JmUZKjNNQhlOmskwW7Bj9LF8RISa6lYwzuNhyGXyAFMkngMB5etlst\nWUcQYWLUKjs5gRxVQ+YY6QBCeL6ltJfKGSf4W0hcI3RixPdZk4xOHzoSmXyxhF5B6a1Av6MUyqR/\niTQAp8+uWyPP9rs3GOlvKFf1UfbILF7vEsd0KHI4nZJ6jAWTz3HMUhZnstj9bsazBkklIXlkPaWX\n/W0zwpKWOGHZ33fqN+as9YXaiyHjuPO925c1nYSUHuN1WXV0KFEaYn+Ju6HkS9nOjlB3knIWHcFJ\n3TXIa5RaWTtwxLk3dLO1qQxTYbxcVP+NpeRYe69jQtKzKCXSbUspjEk/ndIppOZAtxWdd4wP7IzF\nfuAyBMpVWMJBhzQlqqQG6eFlu8Ckp2gr3vDo2M7pHAwcR0wojecal5wgkWaWONXi166a/c+l5JnD\nZ+vOJWF9woE1LFlXDts3mB/kTLyLHbOPZHmibWIb9Ee4fD15hiAha3v5upOKPAkhhBBCTECTJyGE\nEEKICTjdYEIIIYQQ4vYo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT\n0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkII\nIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJ\nkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEII\nMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkych\nhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGIC\nmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQggh\nhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5\nEkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQggh\nJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSE\nEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxA\nkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGE\nEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZP\nQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHE\nBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQ\nQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo\n8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJCCGEEGICmjwJIYQQ\nQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSYgCZPQgghhBAT0ORJ\nCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBCCCHEBDR5EkIIIYSY\ngCZPQgghhBAT0ORJCCGEEGICmjwJIYQQQkxAkychhBBCiAlo8iSEEEIIMQFNnoQQQgghJqDJkxBC\nCCHEBDR5EkIIIYSYgCZPW9z9x939O+/1cYjpuPvHuPtvu/tj7v5f3+vjEZfD3d/k7n/uXh+HuLu4\n+0vc/adu8/ffdffPvJvHJO4+7j66+0fe6+N4Xynu9QEIcQC+1cx+NYTwnHt9IEKISxEu/EMIH383\nD0RcjLu/ycy+NoTwq0fY/YV94KmAIk/iA4Fnm9nv7fuDu6uPfwDj7vm9PgYh7kcOMPb8IAdyj7hv\nHyzu/hx3f91W6nmlmc3wt69z9//g7u9x93/h7k/H3z7X3f8/d3/E3V/u7v+7u3/NPTkJYe7+GjP7\nbDN7ubvfcPefcff/yd3/tbvfNLM/6+5X3f0n3f3dW6no7+Lzmbt/n7v/kbu/0d2/YRtOvm/Hxl3m\nOe7+O9vx9HPuXpndcQyO7v717v77Zvb72/d+wN3ftR3Pv+PuH7t9v3L3f+Tub3b3d2z7Rn1PzvQ+\nxN1f7O5v247N17v7Z2//VLv7T2zf/3fu/kn4zLmcu5X4XuXur9xu+1vu/gn35GTuM9z9J83sWWb2\nr7bX/lu2Y+9r3P3NZvYad/8sd3/rzufYfpm7/x13f8N2bP6muz9zz3f9GXd/y1NJrr0vHxDuXprZ\nL5jZT5jZg2b2KjP70u3fPtvMXmpmf9nMnm5mbzGzV27/9rTtti82s4fM7N+b2afd5cMXIITwOWb2\nb83s60MIV82sNbOvMLPvCiFcMbP/08x+2MyumNmHm9mfNbMXuvtXb3fxN8zsL5rZJ5jZJ5nZF9tT\nPJz8FOMFZva5ZvYRZvafmtl/ebsxCL7IzP60mX2su3+umX2GmX10COGamX2Zmb13u933mNlH26Z9\nP9rMnmlmf++YJyQ2uPvHmNk3mNknb8fmXzSz/7j98xeY2c+a2TUz+yUze/ltdvWFZvbPzewBM/s5\nM/sXijgenxDCC20z9v7Stv1+fvunzzSzP2Gb9jS7/f3yvzWzv2Jmn7cdm19jZktu4O6fZ2Y/Y2Zf\nEkL4tcOdwXG5LydPZvapZlaEEH4ohDCEEF5tZr+5/dtfNbMfCyH8TgihM7O/bWaf6u7PMrPnmdnv\nhhB+MYQwhhB+yMzedU/OQOzCEPAvhhBeu33d2WbwflsIYRlCeLOZfZ+Z/Rfbv7/AzH4whPCOEMJj\nZvayu3bEwmxz7d8VQnjUNg/R59j+Mfhp2zH4OC8NITwWQmhs08antplIeQjh34cQHh+XX2dmL9pu\ne2ab9v2Ku3Vy9zmDmVVm9vHuXoQQ3hJCeNP2b78eQvjlEEIws5+yzeT2Il4XQviFEMJgZt9vG5Xg\nU4965ILw3hrM7CUhhNV27N2JrzWzvxtCeIOZWQjh34UQHsHfv8zM/oltJlevO9gR3wXu18nTM8zs\nD3fee7NtOskztq/NzGx7w33YNr9Yn2Fmb9353NuOd5jifYRt9DTbGCPegvfebJv2NHtim+62rzgu\n/PGxtM0k6On2xDH4XottZoZxF0L4N7aJLr7czN7l7v/U3U/d/YPMbGFmr3P3h939YTP732wTNRZH\nJoTwRjP7W2b2983s3e7+s5Bf34lNl2Y2u41Ufj4mt5Ott9lm3Ip7w5Rn3oeZ2R/c5u/fbGY/H0J4\n/ZM7pLvP/Tp5eoelN2KzjbYbbDOp+vDH33T3E9vcbP9w+7kP2/nchx7tKMX7CsPI77FNZOLZeO/Z\nFifP77C0DRndEHefYGZvt/1j8G0728X/hPDDIYRPMbOPNbM/bmbfYpu2X5rZx4UQHtz+u76VD8Rd\nIITwyhDCZ1gcV9/zPuzm/J7r7m6b8fr2AxyeuDP7JDm+d2abHyhmdr6I/IPw97ea2UfdZt8vMLMv\ncfdvepLHede5XydPv2Fmvbt/o7sX7v58M3vu9m+vtM26i0/YLix9qZm9NoTwFjP717YJQX+hu+e+\nySn0x+7JGYhLEUIYbaPVf/c2GvFsM3uRbaQC2/7tm939Ge5+3TZpD8S95eds/xjcGxV0909x9+e6\ne2FmKzNbm9m4jVL8qJn9420Uytz9mds1UuLI+Cb/2mdvTQCtbdpmuGjz2+zqk939i7cP5hfZpn1f\ne5vtxeF4p5k9novJ7Ynt9Pu2iRo+bzv+vt02Uu3jvMLMvsvdP9rMzN3/lLs/gP293cw+x8y+yd3/\n5pHO4Sjcl5On7TqK55vZV9tGDniBmb16+7fXmNl3mNn/apvoxEeY2Zdv//b4tt9rm1+1f8LMfsvM\nLqP9iuNxpwXe32SbCMQfmNmvmdlPhxB+fPu3HzWzXzGz/8fMXmebCXK/nXSJ47K33bY5ZfaOwQs+\nd9U27fiwmb3JNmPze7d/e7GZvcHMXuvuj9qmrT/mQMcvbk9tmzVmf2Sbh+QH2Wb92j7CBa/NzH7R\nNusWH7HNergv2a5/EsfnZWb2HVvJ+0vtiRHfG2b29Wb2Y7aJDN+0NEL8/bb5gfor7v6YbSZT88c/\nvt3HW83sz5vZi/0p5Fz3zY8z8b6wDSG/zcy+MoTwf9zr4xFPnq3z45+EED7iXh+LEPc77v4SM/uo\nrfNLiPcb7svI05PBN3merm3lhMfzBSmE/BTF3R8POefb/CMvsU3EQwghhNiLJk/T+TQze6OZvdvM\n/pKZfdElLZvi/RM3s39gG8nndbbJVP6Se3pEQggh3q+RbCeEEEIIMQFFnoQQQgghJlAc+wv++hd8\n+nloq+u68/fdopmpruJh5DBCjkN//npWzuIfcNgO00Xh8cNVWWL7DNvj3Ty+P8JcFQIOYnd6ic8P\nY/xPnsfvq0tUDsB+2z6ezxrXosN58hqNA76Mx5fF48uK+L19E/fTdO3565/8N799kAKM3/edn3d+\nQOMQj6dZxu9Cs5pn8eLlWbwmbRO3H3DuZdLGZobPd2PcMT/D65Kh/ddtVFJHXHdDVYdxQH+po7vW\ncX17fNd6tYrboGnyIvbHtN+ZlbNq798Y8WXf4zVLXmNg/L2X/vJB2vM7fuQ1cWy26HdoxK6N5x/Q\nH6tZPJcBuQ2bNrYtDzIveN3j/jluOLg6tF/GNkP/2o2aBzRKMPareHwZjrUoeN/B0WKbDP22QL8Y\nxv19qirR3kXcPsc4retYWu9vPf+TDtKW//BHfi22ZY++j2ud5fE4ee8aR94U47kHvM/7kpnZMMT7\nrqPdeM+mXTXLeH3xh8A2w376AZvQWBc/XHA8GftIPIYc58y23HwI91EcX4n7d45nBPdVFPH9xSLe\nt77xKz/9IO35/b/49vOL0eB+OeIaJc8vXK/k/ornQI/rkuHB1mGbMHK8x32WGCs89xLHUFaxPXit\nzMyqOv7N0Ya8Xww92y2Oo26MxzG0fMDgmYjvGp330HjcfD7w3lFVcTxusi1s+Ntf/hG3bUtFnoQQ\nQgghJnD0yFNZ4isYJeBBYNafZ/zVF9+vMXMtCxRFxy+rgJnrYjY/f51j9snXnAEH/E5yzKxnddzP\n9kPn8NdYgZk2p6uMNq2addwmxzH1cT9VEWfc/DUxBPwiwMw65/Zl3H427hz3ASiL+AurGRAZKNEe\n+AlQ41c463iO+JXYL2ONyODpRL+s4uf5O4ZRJXf+Yox9JKsYkYvXfRjZ83Ad8VlGguY8Bmcbx2vN\nX4BhJ4dcNYvXJr/gt0qBqAyjHjyOLDv8UG1XZ+evu47Rz3hua7QPow1z/NrmMbeMxmLsB+TN63tE\nGBAtLRFd65I2jl/F7Fs3b8Xj33wHotmIJFY1jgM7yxB5cPwSZZ+qEDEahjhO22Tsx/3PZvG6lIio\n8z44R584FMt1jIqy/RipYPGTkERXEc3I4jUc8Yt/3aaRp4AIkydR+/ia+81z3uOxHwbXqTrwD0MS\nV4j7YW1gRB053guqGlk6/qgw8G/DiGgVjpvtnHWMbtjBObv16Plrjk1GV0tETEZs4+ynTRy/HSLn\nCMYm0amW/WgdxyAjSXW1PwLH65MX6UWp0ecHHOvA/oLnXRI9QnQ6Q2Qow/eFbP/zxflMwD573MsS\ntYdRWLt9thpFnoQQQgghJqDJkxBCCCHEBI4u23FBqCPcRxkmT8Lk8S9cd50sfEToflbHMHnwGA6s\nIe1RUishfxQ4NkpELL+UV+kC4HqO8GO/f7H6Egv2sgbylnExZgwt24gQuiN0ydA6wsSUgriQjwvu\nwkGWLaZU9cn5626M31uXWPSJtuEi4aHjgneEXiGvdDsLgDPIBs7FruwLOH8usKaElyxK5UJU9EIu\nVm3WaJuSkly8vkm4Gn1kCLu/R7iYGv0F16ZgmJlSBGW7nP3zQPSUXtDvuhi6b88ei68hhzQ3GFbH\nbQTtVEE677HAvBu46huhdEgSORaDsu3HHsaB9c3kdLiIu/BFfB/3Aob6G0iGPdo8h/Q64r7Qt5B/\nKTGgD1qL+wOkzQEStg2HTwu3WsY2W0OG4WJ2h8RPo4lTdk4WcKMv70jqbMOhi+dD6ZSjuaRsH7hw\nd/9XUP5O7mXYnovTuQC+x/HUNCHYLlwwjn6Yc8E4ZLuMUj0kX+fS+MMQ2lvnrynJFexH9CzgXjn2\nMG2gL2QwEgzYxvB6Tll0wJjgvXXAEgcYSgzSWb9TPcdx3MsmtgTH7IBz4D21WFw5f93C5EMTRjGL\n433E8yVgrNEgQiPMis8Tv/yDU5EnIYQQQogJaPIkhBBCCDGBo8t285MYchvhsskZ6USIj1JdDWmj\nWVL+iu/Pqhgar+o4F6wh59FVV0Oqm0GCo8REJ4ntuAaYE8JomhkpXSGETMccTnoOV47TBYAwZjvA\n9RFiqLOsKdsh/J4hX8cRZLuijKHRokeIlmFi5Lbxgjk2EMZlXhG+vYJcZmaGa8E8TEXGHEnIKzPS\nDcdETHDk5cXebVZnMUzOAD/3SacPXXtjE/czJIJ0KsPxetBNREcmXVn8bJmn8vEhWK6iJDdADqM8\n1S1vnL8OyMnSwa0yQnqjMaqDbHf64NXz15TLuZ813D1OiRTbV7hB1GEn9xBVJpyDQ+enmDBCRh1W\nkJ6QTKqHbEu3XeLKSVylyFVTwblmyGdjh2/LbkA+H7iHAscdcwRx4PUYs4kVLr7fDum1bvD/HuOZ\n7im6DS3gXmb7XXghkbz3S2F0Dxran/dZOqlCiMfGnE1mZs7YAWVY3Kf5mYFScnKoeF4cCO/Rf+m2\nw3eNXbymiWOMWugIVygdiSNzQe2XrOfMd4UlJMwL1WPMUoLrd92ZWezzZxznWMpD3baax+2vwPFe\n0HWMc8vH/Tkku559hLIdzgF9tsguH09S5EkIIYQQYgKaPAkhhBBCTOD4bjs4XZhmnyn0GSpj8kGG\ngDO4p5h8sYaUdIpEmqeL+D5niDVkt6qiRILQfs8wdHo+aZkBhvQhMeVMiMcSApBqkASQzqIc7p7m\nDI4I4Em2u7jPwuNnQ3Z4B0hVxPDpUMFFxvI3cKqwtAnLf2QsscDkdDsS6WhM9ganC7aZIezrQ0wI\n1yTSK+QvSgk4pjpHeB/fW6BkDKWzrqcTjkkY03MYID+5Q66hgwxN1WO/BdxRTIZ6KNomSnIMbzNx\nZXMWt8lxbAyNG5Iyhg7uJoTnW8ir9cnp+Wt206GJjrGRMhGrJcGFU+3KMCy/AQerQw7uMe6GjtIV\n+ifk0r5Fkkncv1iCqaRCDPkn6+nmgoR9BJmnWcW+DzUySTY4sqRKsV8uYTJEJmldt+m9qO0ol0MO\nQrtVaLeaiYqT+yYtdnw+tHvfJ3RP8XnSoy0NywiGXTcvZd4LysTgkiWOvGRZwJhK9YdgffPh89ct\n3GksMZMlSWhxbHTsdrzvom/C2Wbt/vIvMzxPKQUzqSaXwbBd1zv38mZI1unEV3C9MX9xg/tLlUdX\nbcCYz3BPTErMJM5sLAnCvIEORi79GHZL+NwGRZ6EEEIIISagyZMQQgghxASOLtsldWYQ9hzhmGIt\nqUT1gESWuK0QlmQolU6qE6zQp9TGyvY1JLIM8krDMPGObNezBhYlxsRJFbeHemC3zqIsMSRVw1Fj\nDWHDuornEOgAgXMhp3sMzhU7fCQ5cTrk0FtKuBwbhEPXaziPsJ8cDqaRbTnsyDCQDSirZnBWpOoR\n5JmOMmqU3sY1ahohmSnj8xXboIATjnWy0I/KxNmZDqlbTMTIP1BuZagY16OAk/IYSTKzEKUeZ4LV\ndbwuJfp4yTELyauF3FbCVVUNqPkGCY/1Gw11EYuMzlE4aulMRZ8Yd8YmO0PJhH2JlITEs+huFBWy\nYf+5casCtfp4XZic1ft4fXvKk93hrbBLXN+R91P0G76fo//x/sjadHRPhV33G/ZFSTZpk0Q+o8yJ\n+x0r3ScfhiOPLkHc73hEHWukMbku3YY7CWwDa/rxOCi9QjPOk2Zjjb3DuyfHFnUbmcwWMhklT6pi\nXAbAxMkLPEPpnktqiKLNOyxfefSRKCPy2VXjHlUXXL6QDk5ea95r6IykrJqjHuVQ7U+knBVIAApJ\njiKv4zyHNo5l1l0c8Yl2vPxyF0WehBBCCCEmoMmTEEIIIcQEji7blSXkM9gvBjoXEFYvEcZnkkzk\nnrMc4d2ctZEYukQccwEJr4JDgSvu226/5FNXqVySJyFxSIZICFjTobGOocIaifgKyEcOm0GS9BLu\nOYMrgc5DWpFCknzuCPNiSACZU75k/TeEs1nzi/WDIP/Nq+iKzHccgqz/1/XxOuYQwDImQMS1zkuE\nq+eoO3jz5t7tK7TzYhZr+JU1Eq7BAeQ5Eqwm9e/SIVXglNoGkhP0XDrp6KApIFcdw20Xhnj+dICV\nbENc3xxyyHodk4pmcAOVkN5qjM0F3Glz7IdJ/+IISmXRGRyPlOmTGm6Wykxl8j7qrY10UjHZKvoR\nHHnjOsonlIY6JDEMDRLs9ugXkPZGuL4O77Uza5kYE+ORkjrdzkzy6ki6S20qSbS7cz9hDTwbKMrj\nWjPxMD/rlOHgvDPeU/Y7AOmwY41LOrCpW3E/T3TtsT4dnjU4NyYt5q4Ss+IRMhK36HeJ3AiZq0Nf\npvuxgFTFZ0sPeYrPQcqirBfI78p4TTomy0Xy6h7LDHZrISYJkJMihvE4cB1r49KJuNGcSYRxL8jh\num4vqHnIJTSB7mJu3+53uO9DkSchhBBCiAlo8iSEEEIIMYGjy3aIdFsf6IKI87Zixto1DNHSDoOw\nNOo4jazJBUdahzBmA3lmRE02Op7ovGKIudyJ9BZJDTwcHur2Vai3t4A75BSJHlcr1FVjErRA9yAk\nTIQlM4TZmQyyhbSXD4efF49wUjX4rnWH0G1BJw1C7AH1kxKHDULJRerQKJCI88YN1h6LLqacSRPp\nDsL3rddxe0ONsZOoGCYJ8/LEqciEqRCWMiZiY0g6lR7ritJbPNaGySSR1TAbKCthr4fPeWpZhnbD\n2BnhUKKDcUBS0dBBVmggYSFhYDmPdS2rNdxzSL434rN0kdYO+auJx8naf5T/zFJHW4faduOakjzq\nYeECszbWCg67vInn2bDuJMYvXa5lF/vISRXr+XEsVMXhrbANnaNMyAmZi/IXkzw63Wn5/mSW426N\nTzgMc/4tY83OeF1m+G6WM+P9tMc9JamXSQWIiTcha1OCZUjAOYh25LWAnbE+Ix3fGe7rBfoelPrk\nHA5F2+Aeh+NuWjzveGHQvwyuOi4t+f/bu5flNpKsScCRdwAkJVX3v/jN5v1fbqa7qiSSAPI+izGr\n+AJGVQs24CzGjq9QrEQiM26ZOh7uPkJJSTVeLv49n//g1hrov5bflUYv1IhVOTfNI3UOHnrVtlB1\n0M2OtQ762y0O0u6q4KXwHNu7OZWsFaW69u8RladAIBAIBAKBOxAvT4FAIBAIBAJ34PNNMimPmdvV\na5RouZ3vdrzbaW4p1WPpdeFEZ0r153M+/gjNc4C3mRYpxVw+bG6aSOpKQ7kd6i1Bme2UzVWZ9Rgr\njphJmmOUUCg15hjJMW0qWmiX6vEKkHm1rcknUqk0Uz6ln7ZNpdLMZ8rTVVkybeBMOwzRjr2qQinP\nfIxl/xVaEYa4KBmbR7gVGVgYI/LnK6Xny/v3fEwLF5hSenrOv9EVWVSMHbRh+56PUfjRN4/vz/H9\nz78+Vyimrq+o8OjP2pI+ytnpDTrPHLnCrI92lJqnTWqohPYC/YfartWc9KZJWhRXF+b/eM7KQDMo\ntdPTNLJivIxQhvURg0Ku+7o61jDGhKpsoW+7TzBVLCgpc9r2j5VtLWuL9JoqKfPvzPJLqVQxXRio\n9oECPZWaqqhbKKYZGtkHgZl8Heu3Y6HXYBE9oxF50uYplUaJPpt21jnvx/ZTALelx8/NpZhHrkfM\nF6hQtxo4j7zmrTChRRnX0r6cv0XifjhABQ7Svxm9F3GjbFygP1XOD6y7mnV2PDd9D6hVzqKKdZy3\n3PMCHT8zTpczW3nYOjAXWzz+HlF5CgQCgUAgELgD8fIUCAQCgUAgcAc+X21HfVNqpC6OoRRnyZlj\nLFHufDbT54JqaZo+VhCMcy6f91AVM8Zf5idNNyX2GhVBr8EbpeWFrKdE+fFCZtiIcmkurg81UPq4\nfKyqTgWjqg/v4VGYpGEwMVtkQnAqVVXVYn764y3TKFdojqdTWf5eaceu47wHytKo4U4H88ykM3Pb\nSf/W0sJkRml0ue/5us9jPv7yPZd9LYE3Q/nvkQ1DwI2+MpOwr/KYXDZK6y0cY4uR4YPw9prpxorf\nXa+YXmrgyndbaPf6CLVBWd3jn6F9XsyapMsXyuepoPhR1zLu+r4c46djbscBGn6EMjKvay6y1z42\neh1dhaB9Jox3VSLNrfORm4M/KgwmH4RVtRFr7sICqRlix3iXpt5oN2ntdLMNwOWlqqG/UQK3rtlS\n5+SWNaxrLdS0mWQz9EynwSbXUzO+dj7bLsNQruVXTIt3fnvVoFPlYqX6jC0Jn1CDaFn7/F23Zpi7\nt9FGPjcO0Jz1iTWOsT+pXq9U8zGmWscRZpaY90rB3Zqqnvm9I/9Po8ud+dK5ZQW1nYaW5uO6tqyc\n6wAAIABJREFU92dfpfbymlKpnEQ569ai+kbB+3eIylMgEAgEAoHAHYiXp0AgEAgEAoE78P+AtsMQ\n0dwkM+koJ6vi2CnRb5aN65+UnCknXkfKnlzPGTpvfs3lukEVDzKeK9k9KaW0Ux58PuXSfYeC6Mpv\njJgJXqHqztCEm+o5btOSc1ergqBcu+Xrq8yS+4T34nWn3aF55pVrazXcox2hYVbvETrjut6aHmZK\nr0sfq7j6wcw/KJOkYSZKHyiDqjBtzee0VG8V96D6yNLwzPGpxMxfZr5TYWpXQ8kdu6zWa2syGfvH\nZ9t1yAd3uNf+iTZCCXowk5DPK+XwnYzI7TV/rjXCpWT+LDUJNWvW5IYyRjPEtS6ppCphyqmCjDVI\nc8AVKmEvAuekVzEZpI02vttDB61Jo0fz7zh9/ev5Wb+KyUlRu20AOgsl7/oThZhU42CW41auJ22h\njELBfMDoFFp1m1VOf5x5N5iduWt0SCZoLS2av+tzYIba6Vrpn5t7KNxwGReF8TCUDmu8exia9tep\nnl+GdBMU6wqt6rrRQp1qbjkwlqtiSwz0J8+QiTG+uJqxEB6g7FeyL3fWE59dKaXUHqRSmUfSZ6wj\n8+L4NF/UXFMPYW3lmqo5rx27z36yZX3smGv5nxCVp0AgEAgEAoE7EC9PgUAgEAgEAnfg02k7KnHF\nLvhKmRwlvppy4l6U+lD9qLKhXD3z+YI5VlVwhPmcl3MujR6P+fxPKMPmrSxvL2SSVZPGXPnz23s+\n7ztmfRYyZwvWKmV+kkWlAWhNplPN9RUanscLelJL1t6yUw6tMcaDerlCW2hCulF6ryh513XBnaQG\nhYdZZdfC+I/rwzzTDCSHWqXBZqWpm8pJc5LIfKO+W6OqkzG5jmUJf4eeTeS1SSU+nzDSPGCyuaDi\n+gRm4JSHUar8dxSXLI1+wtDwQNstXNz11dI9NPX7az6ee+yeM9V24PMIZX89Q+1eHHflv/1qlrNC\nHAZ93DNfFgxW38m0mrnumiA2FWDrrjqXHD7Gi3mBxThtHj85V+bEyphrzMRkjO/m+pnNh7KrUW11\nE98m5dujVOyYszVrcGnimOd5S5tqbNsnv8schC5tpHY0CeV3W7PTqpJKWuiHxWw7VdTQOCqqzRIc\n9sdT6t//9T//+txD5atYT0e3srBW7D/++rxN0Otm9qlyW+yz3Dez/YfKcZ5tdy6adXO7zRHUPLnY\npuPClo95/dPMS651/5i2JQY1HXg/qLiflWfIzjOaGNz0/kZm539AVJ4CgUAgEAgE7kC8PAUCgUAg\nEAjcgc/PtjOXp1b5AN1E2axDrdEfKYfrh8XnhTLuaH4aZX9z3szYGVGQWPLvUJUtc1nqvWJ0eabe\n9wwHMlK+fMO4s+lV5UD/afyHGizRRl5FQW3uH5dA6+bx+VmN55Qu1CQQNdTrJZdAxznTNnVNhh1l\n1S6V3FTPWKhOT/n7HQrDA9Tpc76mI4abO5zDjBFjRS5gA/UiXXY5Y5hYOXby4WdUTMsGF5Zuxn+R\nPcjYM2MLdVu15Ot7HsrzPgJfvxa2l/kjZfkFFapqqAMKq4Ka5/oH5xQSSzOsWs7TYrhX05dX5yAU\n0eFU5gi2GDSaSTcxH9/JrnpnLv/g7+eV8v4TFPmQx+CGWa5d3EP/98+qhaH5ahM8H4NiPMGYFPSl\n+X38D9VTRPalFhPC4caQVBqyoy0qM+I0dywoHRZ8BWyTVI0qbW/BuYwK060P0HMqQdepXF9mOm5E\nDajS6zqZt8kzRcq4ffxa+/7Hv/N/HKEhMWdtUXnW9ccmtwtrrc8Q81uvxb4GxgLjouV+N54/7mrR\n7LmtyzbpNMjmvNUIrSzzisKydtuN+ZcqXs1tNPMOA8wj37XvXzFtPn//I/0qovIUCAQCgUAgcAfi\n5SkQCAQCgUDgDnw6bWemWUXpbiafrT3kY8wounKM5pQLpeHx+rEJ2KKZHiW6CxRLj9Hf1ffIjyNz\nUkopvXHe2mwsKIN3FEEjypcnsreqSjrTfB/KncgJWtquiBDyWtPH5nOPworScKYcfr7ke1ykP8ZM\n213GXBpt21yeP50onS+lQVmFcq3BDHOAcjhBl25QeOkZ01OkPvNr/u6F6x4w05ugBi4Uuy8oBt9V\nwmGwp7oypZQqEt7sN6nkxHl3qJIKdmNoSvXKI/D1a247Myi3mfvHcK4wBhwo3UNV7ZqQwpJUZA1u\nZo8xDyYN88yXg+YZUWFVqVRnJmicK/TsgunhGRPAK7/xzm+fyfoqzGkbrq/h5mgjKYli2wFmoHX7\n+NnZ9ZnCbFCami9pXtgL13YaVE+psMr3eLxRqjksVowIO9VtbFNwHTxBxxe5pvA2LcrOlTXR58YG\nVbMzLlrUnzI+l/eSLlURtpApOs2ubc5nqKEmz522e3x/zqhT14Iyy2jnTCO3qBxtFyl1M9yk5FbO\n6hgxa7B4EHI9fadZau77dSvnJktcSTFzrT7LWmji/T0/U8wUHPjCoEnqNT9HZsx2W+ZyZ5Ytz6x2\nDpPMQCAQCAQCgU9BvDwFAoFAIBAI3IFPp+3MjemUcvDathX5d5jvmUOFWmeaVeKYZ+Z5KPWq1uCH\nVxQH50JwUEhOvJ1UUZqsKDmfVfSoOPG7ljhRT5kzZEm0NQ8MWmmDVkgYyHWD2XPp4VigqvSCvPJj\n4+K19RxDifxsrh95W9VNqRdq6Al5T69x4VNuox3TuP1AqZt+rk6U+skYU3k5Mr7aFxRWGLRd3/N3\nL6j23q7lPbT0jwZ3ZlQtGrpamEc1c7ilqB6AQ6cCKv9damunT2YoNsmMjXtc6bOadsFTMP1+zXTu\nQjs8m4XGmPox5bL67+fvf31utpKGaSnRzyhhZ+cL81kTT+nJ+iWPqeYLKkzubXWcQ812Peo8nPs6\nqDEY/ofh+Pzlr88l3UJ+Jz9svlzLvfetCi7yDm+UsC6LF6jqlv+h5+3CVoYLNGxTSRerqlTNy5hS\nSQhV07HFoeN4M//qm4afWWsnxsjCQ+vEVotxkmJsP/z8KKzX3F7t8fmvz5o5N+TuFdQhVFjH9gAV\niW1B5/EM4Vmk+amqc5WTJ9blgTE1LTdUJsbOC/2/8Lw3U9C+tZ92KOLerS+sI/Z/A823QsE2UHsn\n1tZ+Lbdd/B2i8hQIBAKBQCBwB+LlKRAIBAKBQOAOfDptZ96c2TfzJp2hSsysNkqUXS6lHzoooD1T\nAIWZFlTdxt/bU6aSVHroEzZh8FXdGKANKAM1Dlves5qsORoOlkuru+VUSrF7kYcFZdR5rbSLxpgo\nYmpL4I8XZ6UVemKrcztsDKPR0jslU+nOBRO6//Ujl0n/cfsqf8jHPfW5/4eX3C5SoZpqFvQBo3zF\nDK9W/WiDofpTPDfvKiE/ppevS9nwfYV5HSZ9GgIeUaT2KLoqWKmlezxt9+Ul37/dtlK6HskedFBd\noDkmlErdCToDhdYVKuTymqm3f0/ZlO7EfDd7baQk/+f3/N31tQxcqxgjI5RGDXXRkSO4m51IoN/Q\nOb7y+XuyNvdRSg7q4gh9BJXSoc57Gh6/7JqJaJ5XgmpeUQdvXEIFbSexZZ5Zm8p9ACydJR3IWu64\ncM0aL9B2mhtquFio3KCMoGObXZPEj7lQM//aplxgpskJlvtfeuc6ouBOZHjS53v7eB52u6AwO+XP\nB+jZnu0IteGXFcpsrlN6dcWE8sQz7sDYH9g20j3nc16gvAa2irw85zG43GwbMbfwwrNygjKroLxV\np+707T7mv/c7ubHQeTVjfmfNumqkuuTrflcGXdDxf4+oPAUCgUAgEAjcgXh5CgQCgUAgELgD8fIU\nCAQCgUAgcAc+fc+TgYUVskZl37t/35SP5vO4l+AIvy9nPk5I4Nn/07A3qcEiYMANV8fsdySp240M\n9fnrS/4+fPI7e2AMzWyQX5olmRqlwrZRPsR2MfTXoFtDUysl5unxm550xVbeavgtt5tW9jw0yFjr\nOvPW05r5fB28U0rpwIaTCYfqqsl9cDjlvWOHYz6ma3Ek57c3HMmLDS060i/5mnQblsafcKK9Lh/v\n7UkppcpwVP+HBtVYBrTsYWsZn8Mn6NsNqC1k3zi1P23sI8PzY7rSXn0eF5XThb0EV8bmj+95n+L6\nlttaP4PxnNt3ZU/Zhf0oOhWnlNKGPcmVYOCXL9lu4umQ94wYsF1hJbDbH+yLahr22OQhnAbG3YG2\nOLJn7zTka/3t6+ODZBPzfWEdNGy7Zq2o2Y/lGroRqprYszady00sNYvZM3Yhy9V0BRICWMtq97Wy\nYOgqvfxkz9qJddYdb3XrWpmv9cBGqutYWltcfuS9NyNpA9d35rY+NzimL9xbPd5s8HkEWF+PNfuQ\nGPPtVvgN5K/iwm5brNio1Ozx6xinA+vSF1zrT+xtumALcXr6mo/n2ej8Syml1x9Ys/Cs7RkXFfua\n3V9Zswa51073loq9mTqpa89g0sSGTc2RVIfujnJSVJ4CgUAgEAgE7kC8PAUCgUAgEAjcgU+n7aSn\nasrqNWW2ptXRW+ollyvrjtIdpb4WGm7R2sBAT+0FkIWfjrksuRIG21DCvUxl+bGGipD2q55zyXJC\n4ksVP7XtT6i06mNqSDuHK2XsnVK8Mnnt3Jfl8bSdrs8T5fnF8EVK7IZnrlU+HsY2dU3ugxm5aUop\nrchJq13bBsJnGywMKPsfGl2787h4ecr91OhCT+l9OedzXqpMK729ZZn8H98ZI1foqUtZwm8GaB/o\nimNPKR76aIVyaZFAt58QDNzhmF1Bl+tQ3COrvyDbHvPlF47vZ93jobWL8fgPQrQJjP7+I7evFMs0\nO9655lbiJqVlyeNnpnR/VcU95PF2eMn9//SE3J7PDdsFapzUddiuGGsNa5bz3bbuusf35TxmDmN6\nz7Qol5N2LL+rif8h5VMpHS/bV3RQHUrDK9ajAZqrgiLXVb6g/1inVyTz7kDo/V1WyxkKa9/zGNwL\n1+ryHnRZ71CoK7+ftQNAur8a9EySwqPwhe0Fzzz7KkOLpzx3jpmZTuwCSfWCdQbbCwbSPgbuMUH5\npfe8rnc03oFtMz1r1CF9vP0kpZQWnpt+7rm3GprQbSHjOc+vZaIT7U+e3zqgtzwfrmzH2IuQZOn1\nn4/5W0TlKRAIBAKBQOAOxMtTIBAIBAKBwB34dNruHQpMj+RKZ1lou8OAgyglvQYX1AVlFBXndKSs\nekKFpVOqijEVGsv2Mb3Yncv3ywM10QG9h+X6nt/uoVs6yvgzaq0ZJZIF/Yny4y61p4m3KhuokfU2\nmPEBkEpR/UeTphMOztZu38+EMtLWKsraWxqGsbNdcXM/ExL9mtvuSmpoQ+ld1d8uXUzfVFKBO7TS\njx9/ff7+70wL/fiD/ttQf6IkTCmljrJ2DeXQUzbvdWtnbOvQXTW/Xk7+VagAG5ePqWOmQhHgvVHe\nX0gZ3VBxrdBENQqzY5M5hnHXeTi7jV8c7zomS+3cpF+7RhykHqFzh/+R5+aX3/Ln05F5Tem+cpxT\n6j90UscqKpmzOGArE/qM0O4dWsxw4jblcVrjPL7i1O3YqglttY+PbHFIKaXTidByxvUETdbvHyce\nuN63/PbTEyHc/NY0w6mxjeI65jXl9Q3Xao5Z+WEdz1NKaUNVXYTgSmG3bAuBSpwr3bAfr4R9oX1N\nQx6h3hZTOhTeuU4TU7CigHNo1gYpQwvuUniXfD3Hb6hfWX///D33wX7z+HFLxuuP1/zbrH0DYe49\nJ/jx7z//+jy+5vU4oRhs2B9zJoT6qJs/tvo7rz6t69RNAPbfISpPgUAgEAgEAncgXp4CgUAgEAgE\n7sCn03YTxnc9JXfDN1vUCqrZVigMDa4OqCRWaKvDIZdSX6DOnglTTJSYLXt+f0VVx+++3JarB1Uq\nGLlRZ+6gHmuol5qDdtVH8F6jJouUwLdZk8x8iMq1mbL09fLrAYe/innVhDOjhV4doN4q+TzaZEIV\nZXBnd/sujyrn/U8okwGlREOAKLe8fyGsFfO1lbK0tM9Mqf+P3/M5f/9X/jxdoGCrPC7qKo+JZwwZ\nU0qpl3KCxuzlw1CK1JWKFaih6vG0XUJZ5Tg1QHWFeqno9Y26fw3lcXwhAJrrr3G8Van3RDt+mb7l\n8xBiO7zkNj19y2rJcS6VsK4jB8NEGbdfvuZzfdXwVhNXKLZ5zGO1QulTQ6Wo2jJjtG40ouT4w+Np\nnvMVM0DYltFg4C23VwNtd3YtmjKlstMH6StraEqpmfL6+jar1svH1ENu63lVAZjv/4iq7JxZn2KN\n29jWMJ7zea4XTC6vWUk1s25sf0PbVSj98KZNDfPxAMX4vn08/rfHi+3S05c8Ng2FH3k2SVsmVWus\nLTtrquHnO/fSQ3n5HPvzzfYlSHjN5xxQ3k3QoMuNWfDGHPz+mvtww6i3P+TvDNDlf/zr978+v0P5\n7Sz4R2j3yznP2QPz8YnQcvt4cgvCGMHAgUAgEAgEAp+CeHkKBAKBQCAQuAOfTttZcmyg3nrKoZbA\nLfb5ZqfpVofSRVPGGopByqeHPugpEy+oZ0ZMEi3JHjHhTCmlgfLotnqFmIhRxk+oVyoURAsl5JkS\n5XzNZcN59PPHpfEZOuRyyaXVV0qjj8LOdXa0g3ljDcqmTmNHFI8vqNNWFIvrRhk6lfcvnfmuYk4l\nDmaV8xvZTQ0KIM1Wd/sj9//bn7Tpq7QiWU/MnL7P9ETXlzSvNFyPaei+aCDJ8VJ1lNaXsWybR2Bb\nUKukj+eO+s+WMT5oAAlN0KCTao6ZzzibBUZ23A7V9s8qUxUd9fbf/vuff30+fct00Xkq26Q3I3Ii\n0+w1UzodFOPLM+o8zHNVZ65/8htMPPMrpe1SzdiE/mu7T+B2wM7a2tR5DO6LCjvUvih535hD+5jb\nqlowvy2TGdMKpbdXqpgYR2Spbczz7qRS1znIRKCfNn5rUzEGheVWC00SF/qsuqkVdPSJdGvb5vZ7\nnTBfHDX3VOX8ePnk4YCy7835yL3Rt28Yo1ZcW9cxFuiDSiW30rg69/lV1eIzFCzmmT1MqH2saWlK\npWLyTC7myJrf8Czr+P75kn/kzDOhgRbfWb8nnhWXq1tEcptq8jqzNg3dr1PqUXkKBAKBQCAQuAPx\n8hQIBAKBQCBwBz4/2w5YHrSop9FjogRq5p25apai5fl2yng1ZWzNFy3Pv3GeDuWFbNN+42gnlZIo\nfc6Wbjnv0KFcktLgvbXH3G/0nqHhOmlO2vHMb53PueR+uZQ5cY/ARO5aqs0LzH+vuEfbfceg79tL\nVlWte77Oy7V8lx8vqJWgP5dLPu5NRZCKuS23xYEcuSfUk8en/HmEehzfoeo2aFso4rnI80N90pf3\n8Ntvv+WvI8s5X1CfoaRrK/sZ88XHe56mBmnNyriupJuYRwtclZ6dbaEwg4KHLu2Y8b/9ltu0byiZ\nP+Vx8fW/MoX3j//Of++eM/07TqUyplaV9D2PhfEH1A3dc2BuHqCb95WbYxxd1/x7MCM/VS2asea1\nrUupRHoENtRDclA1eWMaPo7QwKvZdJoOmzV2E1Y2QrFpNpy8f/I4GwxZG9pxh8K5bG6dQKXcqBhj\n+wL0as1a3NEWXvZ8Yxy8jErsPn5eNDwXOtq1whR5/AQlrPT9RcVncg3K93zhObAxT81t0wBz43n1\nPGAKfEEJB6X6/ZLP33yHyi7kpRhZ39B2TSV9mj+/QsO1bsehP1eeg1eo4AaKfJTORBU7vaPC5Bny\nNEjZ5748Hku19N8hKk+BQCAQCAQCdyBengKBQCAQCATuwKfTdmfKZgfUN83PDMoo0ZrzVVMSlCao\nag0GKdfuGn9B/1AOrCl17qgBPOY2UsxSsXlVqSg5U1r2+/zdEnA7WFrHvIsy8wztdUZxokJlQTUw\nzY+nBlr6bIIv7ShhNx2KlIbspZ6sOdp3QA3SaaqZUlrJjBqv5CEVGX65396h7SzXNyi33sl9ev8j\nZ6m9/siGcJacZyiAPWnCmOmj4h6aMtuuWTV9tbSMGrRxXqA+5D5b2u9R2FGbqlyypE+lO+0ztAXD\nS9biiAFic+K+GLMq1RIl9mdyEU8vUmr5x46nfPw/vpXKxp3r/u6FY9a4StWbrwkPZ1vMyioRsHbu\nF2BuGrbZQHtUqZAlPRwFI8UC2Te5jeYZWp8vDNAofY1hsbR7XS6ES3H7qOE8hnnUQeFNnOtwzH1e\nQflJybqtYxptR/qSe9ZcVhPlZS9rBTZZx/wqutO1ZlOtSBZeejwOjNmuQ22G8mzSRJg+WO1DGLa3\nt0z/qYq8HHmecPOaSP8xotrkuachdMWWg2Urnz9HzKVdIxwLBZttPh/P5hnKt1JJ6t9Xt+PwToCC\nszmggub5W0/l+v13iMpTIBAIBAKBwB2Il6dAIBAIBAKBO/DptN1o3lphMmb5zZwdlCJm8QzmTWE8\nSaH4MGgClr97hpKxNqjRWyu1p7TpJqPHLDZL/Qj9CiPGjfLlCHXRmKVFN2iq+PyU86TOZDddZw3q\nKB9LsTyetSsy2HrVVihp5imXhmeojdr8NijYjs97ydqlAZXcds33XNEnlvQXaDtVT+/kMm1LbkcV\nnBO0gkqXwzErlGZM4BqoytOQ+2m4MclM0HZyGgOl667NpWKp6oX2m+fHZxVWRRggFBPXuTOPBsZ7\nO6jC0/QwD8IDJf3Vc0INtNVPqFYouA2lz35kolUllVltqIzIzEoojhrosy8Y/zkOzxjMHjT0HDwP\nY/6Cokdl1IBhbPUxLfgobCrSUBGqHO7rL3xmbmJUWDM/NPzcm/JRYd7cxnx0G8XOIrTVulDmti5U\nyox3tyw4N6XzzIpcGGAVCs4a6l/aLaVy/s+sIxv03gwFNrGGvRGrOLeP789nclqXL7nfmobxVec+\nmN55JrBOFYtq49YJnkt8Hk4oLFWH03+eUgWjY+35dGMWrI8s47Pm+bhDB+6c7HV2/UbBav9pwsv8\n+ufXvAb1zMeeZ0vf8/7R3Kzff4OoPAUCgUAgEAjcgXh5CgQCgUAgELgDn07bDYdcGq8ooW57/umG\n0qil2Np8I8velBAbbsHd/hZo3ymrq2Yyn0ijrI2d+8utoZ0Gmj/JGZKeUR0wWeqmzFi1qhdQSiD1\nK3KZoFI08ayS6sTHvxfvBTVp/5EjxvHzmL9w4njVFhsUTnPjBLnTds/D1/wdzAfP0IQqqeaJtvY3\nkIZ1mMP1mKfulO0PXc5SO3W5lL6aWVfl79b77ZTSWJLzVpbQpXQYYJvKxcf352Z2leN8/piOPpDz\nWDNf3qGRpUzSlOfdEzTfDA1zkNW0bE9u3frGqII6W5eyrevKPLBMvSmK7VhfVk67J5RIqmKh/7ae\nuSbd1KhOJKsLdWalceMnUOqvZGIeWGd7MghfukxhnDITlLZr3tbQLK6DuU3ON1Sj9HJjU7AGt+RZ\n9qjqdrZITFAytUpT1v6Kfm3NL/SZIO1mXiZ9sKRSMaiCeV/YPuCzgJw7cxhHDH3H9Wa/wQPwj2+5\ng1bGWs/zoTmwJWbPfbiR63jBVDLVH9OL76huU0L9KM23/+TZwhR0C8l2s16p4luhXi+YtRbn3VAD\nXvNcbnefd5j5mruJku7lJa/fz99y2w1Q+b2M8o2q9O8QladAIBAIBAKBOxAvT4FAIBAIBAJ34PNp\nO0r9Uk8NJcGane8JYzmVZy0lZ00ZTyg3NL3TAU3zyJmS4XDI51mLLB4UdbcVWap6Uh3bgtEY9zCh\nDpgob1c/MY3coJsaOJOea+0v+bvHokSfu/OsKd+DYFlVZYSqlY5+LeRTlaZnlF5p93q/NYLMjd+h\nlNg32y5/f91U4mCsp+tdq8oRQ0dqtyrDkoZzdR7Lu4Z59Nl8o+gZUM10/IYqFduyZWwPff6umYwP\ng9lwmqoqVGN+DSpmoJpH2rem3Rfohho6Z2WuHKASpAbMDpQx2s7M2aX8t5/XVEH7aXRYQclcMfCV\nRh+Ym635fyiEt53cNmjkZst/n1F5ju/kXUK9PAqvmCf2mnN2tC9z8AsK2YqcykUllarerbSC3FA2\n7rbdkcxOKHJ3NRRrM3Rms7leQL0x7mb6fCu2LEDnQqNNGCZut6wVY7LppKvyvLtwfRfWnavU4yfk\nTn79LW9TGFmQrjxEpj6P8Z416PKax+P4zmezWGm7wmiZa6iSFCk07SG31XDEVNL+3m5V6qrcXfNZ\nbJkvFed6UUXPlh0pPJWaZpk+f83bhg4v+bq/YX57hMJr619/bkblKRAIBAKBQOAOxMtTIBAIBAKB\nwB34dNrOnDfVNFX9cfnV0l8FR1ahgOpQaw2ouPqf0HbK31Re7UmqZvzwmLopaRgNHs34aVHGNVAR\nszXn6mN6a5nz8eczqpljvj6N6GwvFVxdp/Hi4yU99oEqv8Mpl7nNJ7ucMQ8sqFP6wLL6UlIDmpCO\nUkC4tJ36rEppX6B0NNPDYHOjP5tW1SZlf3PRVgz9to+vp8UxtLsZL4UKCP6pwnTwqaf0zTjqofDq\n6vH/ztFsdEcBt0/ew8f5j+ZeNZbPFfc4HdePz7NzDVLka2FmCy16RhU3lzTvQr+Nuhgybhuuo6Zv\nbN/xHcqQcasJ60p7LVCEO7SdZpjjJSuGNHB9FP7wmqG2Vmi0HbbQ3LomaVpJu7E+3sTCFcrbiXa/\nkNnYYcJasQVBFbXzQwNjqexChbf72XGaz3mlb2SPqlu1GXO1Yg3eWS/OfOUdqu5d+rB6/GP05du3\nvz5fMJfe6OcnOuX0nNv6yvo6HMgjPaMKlcOEanf7itsgPObg+JpZ+6Dz6pv9LprQLphF2z9dp3Le\n9Zj25ZkwMC7c+dN7DNs9vn7Jyrv/+mYeKdtD2l9PKozKUyAQCAQCgcAdiJenQCAQCAQCgTvw6bSd\nZVlNHC0bagy41aoAMAG75HJlB+UxUT/eKQcPA4qZRiUGpX3K8NdZdQ4Km7Es4+2VNByGnhwj+6Ry\nSwO5nf+xYmR2vkoBqHbgeOVHlLG7guax/P4YHFGLTdAZmmQ2lGsP9EGhRoT+aiqNU29AXKhOAAAJ\nMUlEQVSkjfx3MV44pC5Kt1yfeV1DLj+3qmqgnqQSelRbGu5pAtcNUkb8vS2VVFJvUtI9ZWwNR5dk\n2Vzlx6+bt/0qtkUFJLQaSqoFE8Nr9ZqPsQzPHNSgb28/nivScI79vaC+WTegJ2oog+uoJWtKsv/T\nOV93i2pX+rvI6GI+ui7srAUN43bVGBSlj6ok2Tk/N+nx8qwZymt0vVPlSObmFVrEnL6Rtl5Qv9VN\nOa6lnRcouSs8TA/dMjAPvPuF9bjoEFV49j8UubGjE/3k/e9wx9VNrUBTZdezFXPemXNdmBejKt9P\n6M8juabDE8rO0S0orGv05xPbKFSa71gYd8yjlr5VPVe0qbm0GkyyDg6o4rq+pNTNKT3zTjBzTW4j\nUD3p894tMQ1z7YDb7guGrCcMM4/Dx/fpMUP/6/WkqDwFAoFAIBAI3IF4eQoEAoFAIBC4A59O20mr\nVIW6JR+zSWHt7rLPx6zU5CfMtN6gGzqol/FqPtfHBpiT5fnkNfC7c2maNc1Z7dNSijQzT3PAhZPt\nhECZV1TQRwRfbSs03/4xbbdCJZSixcfTPCtmgDvteEbdUlGG73g3t0RuWxd5f2v5Lt9QTpYmWKEG\nNAf07xqxJSim8pz5EE04HbPj9DO1KLQCRpLNgHIupdSSh2eWYpU06EPBCRU1Yya6VL+uAvlVFCV9\nVLGqGRfo7EY6yH5jfq2V7Y4hKQrZXVNR6HjVj6p1VN5M71m19j6W1HShTnQOLvk75vYJaWFzKlUD\n7jhILosmmc7lPEfMI2zNP/zwCv7vUKPerWjHGVPBi2sFY2sn22yaXKOgSG7kdq6Lrt8agC7c6YXz\nbgVVlz/+TFDaSoszpib6xufG1mh+nM+j4vf/fIdr4rybGW2sSVthAsmYvM0/fQC+fMkmmW8YXb6x\n3g3cT888KtZKn7nQWdPsloXcXkfyPl37XIsS43pgXtdQarfPH59fGmEXsk2/z3W77vTQtgN/P50w\nzoa2PJgFCIXbslViOGTl3fNT/u5/QlSeAoFAIBAIBO5AvDwFAoFAIBAI3IFPp+3M6jLPbqcUv1G7\nVTXSoNzZWkzpVFBA1Ywodyz1Da3mW7l82JtzRily4xqWm1Kvpd8Nc7jGDCz4sx2VlOZtoqpVFlBy\nhp7T+OyK4uKKCuJKyNK2P562u4yZslRR2JBJV0GXzLSPvpOaTe4oepaba95t+l3KF5qL9/9FRZfK\ntg6FDm2tsekMldhBdVR8d6P/PEZqzhLw7T2MlL77jnaaNROE5qbNbrOiHoGae664UCkpKWhVZRrM\nFvQf89ru7PecMTWfM8UwvmUj1ZYcwLqlhM8565klqwghTKnm+jpNLzcVPfl4701away2wrhVw0V+\nd6dvzKOU/pWO38m7fBRqMvs21keYl/TGGnJGybmMb399XmfbivXqxthT6s2swpZtFFJAxbjYpIu5\nB/4p3zDvCr9F1M+TlPrmMyQfThencSzX35Ux0ujD2Ep78Vzg+q5sqZiXsm0egZqtAG4P0ZD4K2O2\nUIsyfzWufMc4eMIU1O8OqJGfTh9vodkY/W3xbP34mZ5SSstIpuyXvEZOR/v54y0+ndsrUMMdpd5Q\nWmuc/fKct1G8fM0Kxp7c0Jb3kq4P2i4QCAQCgUDgUxAvT4FAIBAIBAJ34NNpO1VowyGXH1splsIw\n04whje5QJ/F5Q8FmNlJVo/rQ3I7DVVvUlLct+17GsiSrSmG/ZhrLnfyVZWZKkVNR3sd80d/mq5ai\n3y/5ty4osiYpQn6460qTskfgepUizVd6fEIZwev4VogcVcmQL4YSTuPFlFKaqenPmIdqlNZi0lbx\nGy00xggtBrta0H+aJ2oaV4hGVIwkTf/yeBzHslxdq1Li+kYGIpXvwlzOubOuj6cGbEcprxqOtaX8\nXq8qerj/yjGYz++8TsybhgC8ts59s1Hat90a2qSvpebK+7G87zqS6jxWe40imW1zoar1+lCccUTt\nwGAOdtJ2tEtTSQ08nlJfivGB4pXr3FDPLVOmS8dLpu2Wa/6746Mqh3WhmJV7q6CMzkXOoesjn1VV\n0mcN91PR584D79m/X6X2CkVpWSsoFYr0v/whN24upma2y3bTOA9ALSWFSu44QitxmT3018g9X9hq\n8PqWnyFXs0bN6YS/NPtRg2Dbp+H51nDN+802g01TZfrcPlS1WRgv81DRaPvE2q8KT9Phb885z+7l\nJX9uuQaP7/tff25G5SkQCAQCgUDgDsTLUyAQCAQCgcAd+HTa7gz1pkngRslUc0dN6TRBq/Z8no3y\nbodizsriOwaY7txXCef1lHxT/vv11lhtUeEh1ZO/b26dxooqE2qNEbmmK+ffub4JpcSFz4XSCZqn\nax5P25kLqLLCv5v9p7GafTBBH2hOWPKdKemgpwmeBojEZxV0gP8u0IRSc88ZxUxtPhcVfFWbbZ/L\nvipOpOqqG37jBFUt7TdCw3rdPdTCvjvOc+n+UXh+JucP7tjMKPtHKrhSnco12y7S4qrZVD+qSJN5\nsh0dykX2VH0zXqCZzKQz00oj3W7KJ54o46+sKebQ1aXGLl8rf1X96/rSkb11PD6+L81B3FlP3jHt\nPKPyG1HYTddXPmfarvbe69t/Z3+8jkqH1KNqZMZIYQqcz+h51sJ4VJpHRfH+4d9dK7eCvi3XxLou\nJHb5c5P7p+mzMqzpVJWaO/r4GsTpKatTr9yPz6mZ/lS1uKCSXIrMRp6trrvFR/pPRbH5cpq/ogpM\nxbrxc3Wmc96dEH5HBXr1s/UIhV3HuBuYvwe2b/SDOaP5o1tovLb/hKg8BQKBQCAQCNyBeHkKBAKB\nQCAQuAPVvj9eKRAIBAKBQCDw/yui8hQIBAKBQCBwB+LlKRAIBAKBQOAOxMtTIBAIBAKBwB2Il6dA\nIBAIBAKBOxAvT4FAIBAIBAJ3IF6eAoFAIBAIBO5AvDwFAoFAIBAI3IF4eQoEAoFAIBC4A/HyFAgE\nAoFAIHAH4uUpEAgEAoFA4A7Ey1MgEAgEAoHAHYiXp0AgEAgEAoE7EC9PgUAgEAgEAncgXp4CgUAg\nEAgE7kC8PAUCgUAgEAjcgXh5CgQCgUAgELgD8fIUCAQCgUAgcAfi5SkQCAQCgUDgDsTLUyAQCAQC\ngcAdiJenQCAQCAQCgTvwvwFNWD952+j2UQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e7be4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in xrange(10):\n",
    "  plt.subplot(2, 5, i + 1)\n",
    "  \n",
    "  # Rescale the weights to be between 0 and 255\n",
    "  wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "  plt.imshow(wimg.astype('uint8'))\n",
    "  plt.axis('off')\n",
    "  plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
